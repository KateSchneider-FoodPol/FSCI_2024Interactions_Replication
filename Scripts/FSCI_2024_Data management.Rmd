---
title: "FSCI 2024 - Data Management"
author: "Kate Schneider"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

### *Overall Objectives*

This script does the following actions:
1. Imports and merges all of the data for the Food Systems Countdown Initiative indicators to create the updated monitoring dataset for 2024 analysis.
2. Imports and shapes the data from global expert elicitation of interactions between pairs of indicators.
3. Carries out automated literature search for pairs of identified interactions involving at least one governance indicator. The final literature results data set was manually screened for literature in English and relevant to food systems. 

# *Setup and Housekeeping*
```{r setup, warning = FALSE, messages = FALSE, results = "hide", echo = TRUE}
### Setup required to knit this script into a markdown document
    
### Load packages
    # R studio should prompt the installation of any packages not loaded on the instance where this script has been opened
    
    # Data management and multipurpose packages
    library(countrycode)
    library(data.table)
    library(httr)
    library(jsonlite)
    library(kableExtra)
    library(knitr)
    library(labelled)
    library(piggyback)
    library(readr)
    library(readxl)
    library(stringr)
    library(tidyverse)
    library(tidyr)
    library(utils)
    library(zoo)
    library(remotes)
    library(devtools)
    library(dimensionsR) # to install dimensionsR: devtools::install_github("massimoaria/dimensionsR")
    library(readxl)
    library(openxlsx)
    library(tibble)

    # Specific indicator packages
    library(Rilostat)
    library(vdemdata) # Install from GitHub: remotes::install_github("vdeminstitute/vdemdata")

    # Spatial data packages
    library(exactextractr)
    library(geodata)
    library(sf)
    library(terra)
    library(tmap)
    library(osmdata)
    library(s2)
    library(Rcpp)

### File management
  
    # Set the root folder to the project root so that all file paths are relative to the main project folder
    knitr::opts_knit$set('./')
    
    # Set relative directory paths
      data_in <- here::here("Input Data")
      data_out <- here::here("Output Data")
      figtab_out <- here::here("Figures & Tables")

### Set preferred options
    
    # Set the treatment of numbers to numerical (avoids scientific notation from showing in results)
    options(scipen = 999)
  
    # Set echo = FALSE for all code chunks will prevent the code from printing in the output file as the default setting (set to TRUE where relevant)
    knitr::opts_chunk$set(echo = FALSE)

### Functions
    
    # Create a "not in" operator
    `%notin%` <- Negate(`%in%`) 
    
    # Get data functions
    # Get data from FAO API and extract into data frame - JSON format
    getdata_fao <- function(x) {
      url = paste0(path, x, options)
      res = httr::GET(url)
      data = jsonlite::fromJSON(rawToChar(res$content))
      data = data[["data"]]
      return(data)
      Sys.sleep(1)  # Add a 1-second delay between requests to avoid overloading the API
    }
      
    # Modify getdata function to download and read in excel and csv files
    getdata2 <- function(x) {
        url = paste0(path, x, options)
        destfile <- tempfile ()
        download.file (url, destfile, mode = 'wb')
        res = readxl::read_excel(destfile)
    }
    getdata3 <- function(x) {
        url = paste0(path, x, options)
        destfile <- tempfile ()
        download.file (url, destfile, mode = 'wb')
        res = read.csv(destfile, header = TRUE)
    }

    # Get data function for the configuration of the SDGs API
    getdata_sdg <-function(x){
            url = paste0(path, x, options)
      datcall <- jsonlite::fromJSON(url)
    
      indicator<-as.data.frame(datcall$data)
    
      return(indicator)
    }
        
    # Get WB data
    getwbdata <- function(x) {
    wb_data <- wbstats::wb(country = "all",
                     indicator = x,
                     startdate = 2000,
                     enddate = 2023,
                     removeNA = FALSE)
    }

      
### Color palettes
    themes_colors <- c("#21908dff", "#3b518bff", "#97a4b2", "#fde725ff", "#5cc863ff")
    
### Organization
    col_order <- c("country", "M49_code", "ISO3", "indicator", 
           "year", "value", "unit")
    row_order <- c("country", "year", "variable_order")
    
### DimensionsR API
    # to access DimensionR token: 
    #   1. create .Renviron file in the same folder as the rmd file 
    #   2. set the .Renviron file in the following format: 
    #     username = "your_username"
    #     password = "your_password"
    
    # set API token 
        token <- dimensionsR::dsAuth(username = Sys.getenv("username"),
                                     password = Sys.getenv("password"))

```


# *Build updated monitoring dataset*

$~$

#### Import Data
Data are imported by data source. First we import all sources that have an API. Next we import data from other direct downloads. Last, we import data that has to be manually downloaded first. Manually downloaded data are contained in the R project sub-folder "Input Data".
```{r, warning = FALSE, messages = FALSE, cache = TRUE}

################################################################################

###############################################
#   FAOSTAT                                   #
###############################################

### Get all the data from FAOSTAT API:
    # We break the APIs into 3 components, the path and the options are constant for every indicator query
    # The queries are specific to the indicator
      path <- "https://faostatservices.fao.org/api/v1/en/data/"    
      queries <- c("CAHD?area=_1&area_cs=M49&element=6120&item=7004&year=_1",
                  "FBS?area=_1&area_cs=M49&element=645&item=2918&year=_1",
                  "FBS?area=_1&area_cs=M49&element=645&item=2919&year=_1",
                  "FS?area=_1&area_cs=M49&element=6120&item=21009&year3=_1",
                  "FS?area=_1&area_cs=M49&element=6120&item=21004&year3=_1",
                  "CAHD?area=_1&area_cs=M49&element=6120&item=7005&year=_1",
                  "EI?area=_1&area_cs=M49&element=7176&item=867&year=_1",
                  "EI?area=_1&area_cs=M49&element=7176&item=1718&year=_1",
                  "EI?area=_1&area_cs=M49&element=7176&item=882&year=_1",
                  "EI?area=_1&area_cs=M49&element=7176&item=27&year=_1",
                  "EI?area=_1&area_cs=M49&element=2510&item=1718&year=_1",
                  "EI?area=_1&area_cs=M49&element=2510&item=27&year=_1",
                  "EI?area=_1&area_cs=M49&element=2510&item=867&year=_1",
                  "EI?area=_1&area_cs=M49&element=2510&item=882&year=_1",
                  "QCL?area=_1&area_cs=M49&element=2413&item=867&year=_1",
                  "QCL?area=_1&area_cs=M49&element=2413&item=1717&year=_1",
                  "QCL?area=_1&area_cs=M49&element=2413&item=1738&year=_1",
                  "QCL?area=_1&area_cs=M49&element=2413&item=1735&year=_1",
                  "QCL?area=_1&area_cs=M49&element=2413&item=882&year=_1",
                  "MK?area=_1&area_cs=M49&element=6103&item=22016&year=_1",
                  "FS?area=_1&area_cs=M49&element=6120&item=21031&year3=_1",
                  "ESB?area=_1&area_cs=M49&element=7290&item=5081&year=_1",
                  "RP?area=_1&area_cs=M49&element=5159&item=1357&year=_1",
                  "RL?area=_1&area_cs=M49&element=5110&item=6610&year=_1", 
                  "RL?area=_1&area_cs=M49&element=5110&item=6620&year=_1", 
                  "RL?area=_1&area_cs=M49&element=5110&item=6600&year=_1",
                  "QCL?area=_1&area_cs=M49&element=2312&item=1717&year=_1",
                  "QCL?area=_1&area_cs=M49&element=2312&item=1738&year=_1",
                  "QCL?area=_1&area_cs=M49&element=2312&item=1735&year=_1",
                  "QCL?area=_1&area_cs=M49&element=2313&item=1806&year=_1",
                  "QCL?area=_1&area_cs=M49&element=2313&item=1780&year=_1")
      # Separate query for GHG emissions because it has 8 columns  
      queries_8cols <- c("GT?area=_1&area_cs=M49&element=723113&item=6518&year=_1&source=3050")
      
      # Rest of API strings (constant over queries):  
      options <- "&show_codes=true&show_unit=true&show_flags=false&show_notes=false&null_values=false&datasource=PRODUCTION_AWS"
      
    # Run the function over list of queries, separating by the returned number of columns
      result <- lapply(queries, FUN = getdata_fao)
      result_8cols <- lapply(queries_8cols, FUN = getdata_fao)
        
    # Bind rows
      fao_data <- do.call(rbind, result)
      data2 <- do.call(rbind, result_8cols) %>%
        select(-c(Source, "Source Code"))
      fao_data <- rbind(fao_data, data2)
        
    # Data cleaning
      names(fao_data)
      unique(fao_data$Item)
      # Create a list of elements to exclude:
      toexclude = c("Prevalence of moderate or severe food insecurity in the female adult population (percent) (3-year average)", 
                    "Prevalence of moderate or severe food insecurity in the female adult population (percent) (annual value)",
                    "Prevalence of moderate or severe food insecurity in the male adult population (percent) (3-year average)",
                    "Prevalence of moderate or severe food insecurity in the male adult population (percent) (annual value)",
                    "Prevalence of moderate or severe food insecurity in the rural adult population (percent) (annual value)",
                    "Prevalence of moderate or severe food insecurity in the total population (percent) (annual value)",
                    "Prevalence of moderate or severe food insecurity in the town and semi-dense area adult population (percent) (annual value)",
                    "Prevalence of moderate or severe food insecurity in the urban adult population (percent) (annual value)",
                    "Prevalence of undernourishment (percent) (annual value)")
        
    # Assign 3-year average to midpoint year for food insecurity and prevalence of undernourishment
      # The annual data are only made available for aggregate country groups, only 3-year averages are available at the country level. To align with our country-year unit of analysis we have to assign the 3-year average to a single year. We select the midpoint year. 
      fao_data <- fao_data %>%
      # Keep only the total population and 3-year average value for FIES & 3-year average value for PoU
        filter(Item %notin% toexclude) 
      
      # Checks:
        unique(fao_data$Year)
        unique(fao_data$Item)
        unique(fao_data$Element)
        
      # Deal with multi-year averages by assigning observation to the midpoint year:
        fao_data <- fao_data %>%
          mutate(Year = case_when(Year == "2000-2002" ~ "2001",
                                  Year == "2001-2003" ~ "2002",
                                  Year == "2002-2004" ~ "2003",
                                  Year == "2003-2005" ~ "2004",
                                  Year == "2004-2006" ~ "2005",
                                  Year == "2005-2007" ~ "2006",
                                  Year == "2006-2008" ~ "2007",
                                  Year == "2007-2009" ~ "2008",
                                  Year == "2008-2010" ~ "2009",
                                  Year == "2009-2011" ~ "2010",
                                  Year == "2010-2012" ~ "2011",
                                  Year == "2011-2013" ~ "2012",
                                  Year == "2012-2014" ~ "2013",
                                  Year == "2013-2015" ~ "2014",
                                  Year == "2014-2016" ~ "2015",
                                  Year == "2015-2017" ~ "2016",
                                  Year == "2016-2018" ~ "2017",
                                  Year == "2017-2019" ~ "2018",
                                  Year == "2018-2020" ~ "2019",
                                  Year == "2019-2021" ~ "2020",
                                  Year == "2020-2022" ~ "2021",
                                  TRUE ~ Year),
                 Element = case_when(Item == "Prevalence of moderate or severe food insecurity in the total population (percent) (3-year average)" ~ "% Population experiencing moderate or severe food insecurity (SDG 2.1.2)",
                                  Item == "Prevalence of undernourishment (percent) (3-year average)" ~ "PoU: Prevalence of Undernourishment (SDG 2.1.1)",
                                  TRUE ~ Element),
                 Year = as.numeric(Year))

    fao_data <- fao_data %>%
      rename(year = Year, country = Area, unit = Unit, value = Value, M49_code = "Area Code (M49)") %>%
      select(-c("Domain Code","Domain","Element Code","Item Code","Year Code")) %>%
      filter(year >= 2000) %>%
      mutate(Element = case_when(Element == "Value" ~ Item,
                                 TRUE ~ Element),
             Item = case_when(Element == Item ~ "",
                              TRUE ~ Item),
             M49_code = as.numeric(M49_code)) %>%
      rename(indicator = Element,
             item = Item)

    # Now combine the item into the indicator name
      fao_data <- fao_data %>%
        mutate(indicator = as.factor(indicator),
               item = as.factor(item)) %>%
        droplevels()
  
      fao_data <- fao_data %>%
        mutate(indicator = case_when(indicator == "Share of GDP from agriculture" ~ "Share of agriculture in GDP",
                                     indicator == "Emissions intensity" & item == "Cereals excluding rice" ~ "Emissions intensity, cereals (excl. rice)",
                                     indicator == "Emissions intensity" & item == "Raw milk of cattle" ~ "Emissions intensity, milk",
                                     indicator == "Emissions intensity" & item == "Rice" ~ "Emissions intensity, rice",
                                     indicator == "Emissions intensity" & item == "Meat of cattle with the bone, fresh or chilled" ~ "Emissions intensity, beef",
                                     indicator == "Yield" & item == "Cereals, primary" ~ "Yield, cereals",
                                     indicator == "Yield/Carcass Weight" & item == "Meat of cattle with the bone, fresh or chilled" ~ "Yield, beef",
                                     indicator == "Yield" & item == "Fruit Primary" ~ "Yield, fruit",
                                     indicator == "Yield" & item == "Raw milk of cattle" ~ "Yield, milk",
                                     indicator == "Yield" & item == "Vegetables Primary" ~ "Yield, vegetables",
                                     indicator == "Food supply quantity (kg/capita/yr)" & item == "Fruits - Excluding Wine" ~ "Availability of fruits and vegetables per capita, fruits",
                                     indicator == "Food supply quantity (kg/capita/yr)" & item == "Vegetables" ~ "Availability of fruits and vegetables per capita, vegetables",
                                     indicator == "Emissions (CO2eq) (AR5)" ~ "Total food system emissions (CO2eq) (AR5)",
                                     indicator == "Area" & item == "Cropland" ~ "Cropland area",
                                     indicator == "Area" & item == "Agricultural land" ~ "Agricultural land area",
                                     indicator == "Area" & item == "Country area" ~ "Country land area",
                                     indicator == "Use per area of cropland" & item == "Pesticides (total)" ~ "Pesticide use per area of cropland",
                                     indicator == "Production" & item == "Meat of cattle with the bone, fresh or chilled" ~ "Total production (denominator of emissions intensity), beef",
                                     indicator == "Production" & item == "Raw milk of cattle" ~ "Total production (denominator of emissions intensity), milk",
                                     indicator == "Production" & item == "Cereals excluding rice" ~ "Total production (denominator of emissions intensity), cereals (excl. rice)",
                                     indicator == "Production" & item == "Rice" ~ "Total production (denominator of emissions intensity), rice",
                                     indicator == "Producing Animals/Slaughtered" & item == "Beef and Buffalo Meat, primary" ~ "Slaughtered animals (denominator of yield values), beef",
                                     indicator == "Milk Animals" & item == "Milk, Total" ~ "Producing animals (denominator of yield values), milk",
                                     indicator == "Area harvested" & item == "Cereals, primary" ~ "Area harvested (denominator of yield values), cereals",
                                     indicator == "Area harvested" & item == "Fruit Primary" ~ "Area harvested (denominator of yield values), fruit",
                                     indicator == "Area harvested" & item == "Vegetables Primary" ~ "Area harvested (denominator of yield values), vegetables",
                                     TRUE ~ indicator))
    
    # Transform yields into tonnes/ha (from 100g/ha) and kg/animal (from 100g/animal) so that we have the same units of measure across items for yield indicator
      fao_data <- fao_data %>%
        mutate(value = as.numeric(value),
               value = case_when(str_detect(indicator, pattern = "^Yield") & item == "Meat of cattle with the bone, fresh or chilled" ~ value/10,
                                 str_detect(indicator, pattern = "^Yield") & item == "Raw milk of cattle" ~ value/10,
                                 str_detect(indicator, pattern = "^Yield") & item == "Cereals, primary" ~ value/10000,
                                 str_detect(indicator, pattern = "^Yield") & item == "Fruit Primary" ~ value/10000,
                                 str_detect(indicator, pattern = "^Yield") & item == "Vegetables Primary" ~ value/10000,
                                 TRUE ~ value),
               unit = case_when(str_detect(indicator, pattern = "^Yield") & item == "Meat of cattle with the bone, fresh or chilled" ~ "kg/animal",
                                 str_detect(indicator, pattern = "^Yield") & item == "Raw milk of cattle" ~ "kg/animal",
                                 str_detect(indicator, pattern = "^Yield") & item == "Cereals, primary" ~ "tonnes/ha",
                                 str_detect(indicator, pattern = "^Yield") & item == "Fruit Primary" ~ "tonnes/ha",
                                 str_detect(indicator, pattern = "^Yield") & item == "Vegetables Primary" ~ "tonnes/ha",
                                TRUE ~ unit))
        
    # Transform fruit and vegetable availability to grams/day (from kg/capita/year)
      fao_data <- fao_data %>%
        mutate(value = case_when(str_detect(indicator, pattern = "^Availability of fruits and vegetables") ~ (value*1000)/365,
                                 TRUE ~ value),
               unit = case_when(str_detect(indicator, pattern = "^Availability of fruits and vegetables") ~ "g/day",
                                TRUE ~ unit))
        
    # Clarify remaining units and indicator names
      fao_data <- fao_data %>% 
        select(-c(item)) %>%
        mutate(unit = case_when(str_detect(indicator, pattern = "^Emissions intensity") ~ "kg CO2eq/kg product",
                                str_detect(indicator, pattern = "^Total production") ~ "tonnes",
                                indicator == "Share of GDP US$" ~ "% GDP",
                                indicator == "Cost of a healthy diet (PPP dollar per person per day)" ~ "PPP dollar per day",
                                indicator == "Percentage of the population unable to afford a healthy diet (percent)" ~ "%",
                                indicator == "Per capita food supply variability (kcal/cap/day)" ~ "kcal/day",
                                indicator == "Total food system emissions (CO2eq) (AR5)" ~ "kt CO2eq (AR5)",
                                           TRUE ~ unit),
               indicator = case_when(indicator == "Share of GDP US$" ~ "Share of agriculture in GDP",
                                     indicator == "Cost of a healthy diet (PPP dollar per person per day)" ~ "Cost of a healthy diet per capita",
                                     indicator == "Percentage of the population unable to afford a healthy diet (percent)" ~ "% Population who cannot afford a healthy diet",
                                     indicator == "Per capita food supply variability (kcal/cap/day)" ~ "Food supply variability per capita",
                                     indicator == "Total food system emissions (CO2eq) (AR5)" ~ "Agri-food systems greenhouse gas emissions",
                                     TRUE ~ indicator))
      fao_data <- fao_data %>% 
        mutate(year = as.numeric(year),
               M49_code = as.numeric(M49_code))
    
    # Add ISO codes and get correct UN country name
      fao_data$ISO3 <- countrycode::countrycode(fao_data$M49_code, origin = 'un', destination = 'iso3c', warn = TRUE, nomatch = NA)
      fao_data$country2 <- countrycode::countrycode(fao_data$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)
      fao_data <- fao_data %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                           TRUE ~ country2)) %>%
        select(-c(country)) %>% rename(country = country2)
        
    # Eliminate observations with no ISO3 code (regional groupings)
      fao_data <- fao_data %>%
        filter(!(is.na(ISO3)))
        
    # Calculate cropland change
      croplandchange <- fao_data %>%
        filter(indicator == "Cropland area") %>%
        arrange(country, year) %>%
        group_by(country) %>%
        mutate(landarea = as.numeric(value),
               lagarea = dplyr::lag(landarea),
               fd = landarea - lagarea,
               yearonyearchange = ((landarea-lagarea)/landarea)*100,
               # Take 5 year rolling mean as the *previous* 5 years, designated using align = right
               fiveyearmean = zoo::rollmean(yearonyearchange, k = 5, fill = NA, align = "right")) %>%
        ungroup()
    
    # Rename     
      croplandchange <- croplandchange %>%
        select(-c(value, landarea,lagarea, fd, yearonyearchange)) %>%
        rename(value = fiveyearmean) %>%
        mutate(indicator = "Cropland area change",
               unit = "%")
    
    # Append to fao_data
      fao_data <- rbind(fao_data, croplandchange)
        
    # Clean up
      rm(croplandchange, toexclude, data, data2, result, result_8cols, path, queries, queries_8cols, url)

    # Organize
      fao_data <- fao_data[, col_order]

    # Pull the food price index separately because the data are monthly
      path <- "https://faostatservices.fao.org/api/v1/en/data/"    
      queries <- c("CP?area=_1&area_cs=M49&element=6120&item=23013&year=_1&month=_1")
      options <- "&show_codes=true&show_unit=true&show_flags=false&show_notes=false&null_values=false&datasource=PRODUCTION_AWS"

    # Get the data
    result <- lapply(queries, FUN = getdata_fao)
    fpi <- as.data.frame(result) %>% 
      filter(Item == "Consumer Prices, Food Indices (2015 = 100)") %>%
      rename(year = Year, country = Area, unit = Unit, value = Value, M49_code = "Area.Code..M49.") %>%
      select(-c("Domain.Code","Domain","Element.Code","Item.Code","Year.Code", "Months.Code", "Element")) %>%
      filter(year >= 2000 & year <=2022) %>%
      rename(indicator = Item) %>%
      mutate(month = recode(Months,
        January = 01,
        February = 02,
        March = 03,
        April = 04,
        May = 05,
        June = 06,
        July = 07,
        August = 08,
        September = 09,
        October = 10,
        November = 11,
        December = 12)) %>%
        select(-c(Months)) %>%
        mutate(date = as.Date(paste(year, month, "01", sep = "-"), format = "%Y-%m-%d"))

    fpi <- fpi %>%
      rename(CPI_food = value) %>%
      arrange(country, date) %>%
      group_by(country) %>%
      mutate(CPI_food = as.numeric(CPI_food),
             log_CPI_food = log(CPI_food),
             laglogCPI_food = dplyr::lag(log_CPI_food),
             logfd = (log_CPI_food - laglogCPI_food),
             abs_logfd = abs(logfd)) %>%
      ungroup() 
    
    fpi <- fpi %>%
      group_by(country, year) %>%
      mutate(sdlogfd = sd(abs_logfd, na.rm = TRUE),
             meanlogfd = mean(abs_logfd, na.rm = TRUE),
             fpi_cv = (sdlogfd/meanlogfd)) %>%
      ungroup()

    fpi <- fpi %>% 
      select(-c(log_CPI_food,laglogCPI_food, logfd, abs_logfd, sdlogfd, meanlogfd)) %>%
      rename(value = fpi_cv) %>%
      mutate(indicator = "Food price volatility",
             unit = "index",
             M49_code = as.numeric(M49_code))
    
    # Remove monthly level data
      fpi <- fpi %>% select(-c(month, date))
      fpi <- fpi %>% unique()

    # Add ISO codes and get correct UN country name
      fpi$ISO3 <- countrycode::countrycode(fpi$M49_code, origin = 'un', destination = 'iso3c', warn = TRUE, nomatch = NA)
      fpi$country2 <- countrycode::countrycode(fpi$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      fpi <- fpi %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                           TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))
        
    # Organize
      fpi <- fpi[, col_order]
      fpi <- fpi %>% unique()
  
    # Append to fao_data
      fao_data <- rbind(fao_data, fpi)

    # Clean up
      rm(result, fpi, path, queries, extract, options)
    
    # Save
      saveRDS(fao_data, file = file.path(data_out, "faodata.rds"))
        
################################################################################

###############################################
#   SDG (UNStats)                             #
###############################################
    
### Get data from SDG API:
    path = c("https://unstats.un.org/sdgs/UNSDGAPIV5/v1/sdg/Indicator/Data?")    
    queries = c("indicator=5.a.1&dimensions=%5B%7Bname%3A%22Sex%22%2Cvalues%3A%5B%22FEMALE%22%5D%7D%5D",
                "indicator=16.10.2",
                "indicator=2.5.1&indicator=series%3DER_GRF_ANIMKPT",
                "indicator=2.5.1&indicator=series%3DER_GRF_PLNTSTOR",
                "indicator=6.1.1&location=ALLAREA")
    options = c("&areaCode=_1&pageSize=20000")
    result <- lapply(queries, FUN = getdata_sdg)
    
    # Create data frame per indicator to wrangle
      sdg_5a1 <- result[[1]] %>% jsonlite::flatten() %>%
        select(c("seriesDescription", "geoAreaCode", "geoAreaName",
                "timePeriodStart", "value", "dimensions.Sex")) %>%
        rename(indicator = seriesDescription,
               M49_code = geoAreaCode,
               country = geoAreaName,
               year = timePeriodStart,
               sex = dimensions.Sex) %>%
        mutate(indicator = "Share of women among owners or rights-bearers of agricultural land (SDG 5.a.1)") %>%
        select(-c(sex)) %>%
        mutate(unit = "% landholdings")
      
      sdg_16102 <- result[[2]] %>% jsonlite::flatten() %>%
        select(c("seriesDescription", "geoAreaCode", "geoAreaName",
                "timePeriodStart", "value")) %>%
        rename(indicator = seriesDescription,
               M49_code = geoAreaCode,
               country = geoAreaName,
               year = timePeriodStart) %>%
        mutate(indicator = "Guarantees for public access to information (SDG 16.10.2)",
               unit = "binary")
      
    # Note that the access to information indicator brings in the latest year only, to track any change, prior years must be also added
      accessinfo2021 <- read.csv(file = file.path(data_in, "accessinfo_2021.csv"))
      accessinfo2021 <- accessinfo2021 %>%
        select(2:3, 19,21) %>% 
        mutate(indicator = "Guarantees for public access to information (SDG 16.10.2)",
               unit = "binary") %>%
        rename(value = accessinfo,
               M49_code = m49_code)
      
    # Save the 2022 values for future use
      write.csv(sdg_16102, file.path(data_out, "accessinfo_2022.csv"))

      sdg_251animal <- result[[3]] %>% jsonlite::flatten() %>%
        select(c("seriesDescription", "geoAreaCode", "geoAreaName",
                "timePeriodStart", "value")) %>%
        rename(indicator = seriesDescription,
               M49_code = geoAreaCode,
               country = geoAreaName,
               year = timePeriodStart) %>%
        filter(indicator == "Number of local breeds for which sufficient genetic resources are stored for reconstitution") %>%
        mutate(indicator = "Number of (b) animal genetic resources for food and agriculture secured in either medium- or long-term conservation facilities (SDG 2.5.1)") %>%
        mutate(unit = "number")
      
      sdg_251plant <- result[[4]] %>% jsonlite::flatten() %>%
        select(c("seriesDescription", "geoAreaCode", "geoAreaName",
                "timePeriodStart", "value")) %>%
        rename(indicator = seriesDescription,
               M49_code = geoAreaCode,
               country = geoAreaName,
               year = timePeriodStart) %>%
        filter(indicator == "Plant genetic resources accessions stored ex situ (number)") %>%
        mutate(indicator = "Number of (a) plant genetic resources for food and agriculture secured in either medium- or long-term conservation facilities (SDG 2.5.1)") %>%
        mutate(unit = "number")
      
      sdg_611 <- result[[5]] %>% jsonlite::flatten()
      # Note that the location dimension is incorrect and all data say "ALLAREA"
      # However, after manually checking, we can see that the first observation per country-year is the all areas, the next if it exists (and does not exist for all country-years), is rural, the last is urban (see: https://unstats.un.org/sdgs/dataportal/database). 
      sdg_611 <- sdg_611 %>%
        select(c("seriesDescription", "geoAreaCode", "geoAreaName",
                "timePeriodStart", "value")) %>% 
        rename(indicator = seriesDescription,
               M49_code = geoAreaCode,
               country = geoAreaName,
               year = timePeriodStart) %>%
        group_by(country, year) %>%
        filter(row_number(value) == 1) %>%
        ungroup() %>%
        mutate(indicator = "% population using safely managed drinking water services (SDG 6.1.1)") %>%
        mutate(unit = "% population")
  
      sdg_data <- rbind(sdg_5a1, sdg_16102, accessinfo2021, sdg_251animal, sdg_251plant, sdg_611)
      sdg_data <- sdg_data %>%
        mutate(value = case_when(value == "NaN" ~ "",
                                 TRUE ~ value),
               value = as.numeric(value),
               M49_code = as.numeric(M49_code)) 
    
    # Add ISO codes and get correct UN country name
      sdg_data$ISO3 <- countrycode::countrycode(sdg_data$M49_code, origin = 'un', destination = 'iso3c', warn = TRUE, nomatch = NA)
      sdg_data$country2 <- countrycode::countrycode(sdg_data$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      sdg_data <- sdg_data %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                           TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3))) %>%
        filter(year>=2000)
    
    # Organize
      sdg_data <- sdg_data[, col_order]
    
    # Clean up
      rm(path, queries, options, extract, result, sdg_5a1, sdg_16102, accessinfo2021,
         sdg_251animal, sdg_251plant, sdg_611)
      
    # Save
      saveRDS(sdg_data, file = file.path(data_out, "sdg_data.rds"))
   
################################################################################

###############################################
#   Global diet quality project               #
###############################################

### Get data from Global diet quality project API
    path = c("http://dietquality.org/api/indicators/")
    queries = c("mdd-w", "all-5", "ncd-protect", "ncd-risk", "zero-vegetable-or-fruit-consumption", "soft-drinks-soda-energy-drinks-sports-drinks")
    options = c("/csv")
    result = lapply(queries, FUN = getdata3)
    gdq_data <- do.call(rbind, result)
    gdq_data <- gdq_data %>%
      arrange(Country, Indicator, Year) %>%
      filter(Subgroup == "All") %>% 
      select(-c(5:6, 9:10)) %>%
      rename_with(tolower) %>%
      rename(ISO3 = iso3) %>%
      mutate(indicator = case_when(str_detect(indicator, "^Soft drink") ~ "Soft drink consumption",
                                   str_detect(indicator, "^Zero") ~ "Zero fruit or vegetable consumption, adults",
                                   str_detect(indicator, "^MDD-W") ~ "MDD-W: minimum dietary diversity for women",
                                   str_detect(indicator, "^All-5") ~ "All-5: consumption of all 5 food groups",
                                   TRUE ~ indicator),
             unit = case_when(unit == "Points" ~ "score (points out of 9)",
                              TRUE ~ unit))
    # Add M49 codes and country names
      gdq_data$M49_code <- countrycode::countrycode(gdq_data$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)
      gdq_data$country2 <- countrycode::countrycode(gdq_data$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      gdq_data <- gdq_data %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                           TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))
      
    # Organize
      gdq_data <- gdq_data[, col_order]
    
    # Clean up
      rm(path, queries, options, result)

    # Save
      saveRDS(gdq_data, file = file.path(data_out, "gdq_data.rds"))

################################################################################

###############################################
#   UNICEF                                    #
###############################################
       
### Get data from UNICEF API:
    path <- "https://sdmx.data.unicef.org/ws/public/sdmxapi/rest/data/UNICEF,"
    queries = c("NUTRITION,1.0/.NT_CF_MDD._T.M6T23._T._T._T._T",
                "NUTRITION,1.0/.NT_CF_ZEROFV._T.M6T23._T._T._T._T",
                "PT,1.0/.PT_CHLD_5-17_LBR_ECON._T.Y5T17._T._T._T._T")
    options <- "?format=excel"
    result = lapply(queries, FUN = getdata2)
    
    MDD_iycf <- result[[1]] %>% as.data.frame() 
      MDD_iycf <- MDD_iycf[20:121,]
      MDD_iycf <- MDD_iycf %>%
        # Remove observations from within the 2019 year
        select(-c(17:18)) 
      col_names <- seq(from = 2005, to = 2020)
      newnames <- c("ISO3", col_names)
      colnames(MDD_iycf) <- newnames
      MDD_iycf <- MDD_iycf[2:121,]
      MDD_iycf <- MDD_iycf %>%
        pivot_longer(2:17, names_to = "year", values_to = "value") %>%
        mutate(indicator = "MDD (IYCF):  minimum dietary diversity for infants and young children",
               unit = "% population, 6-23 months") %>%
        filter(!(is.na(ISO3)))
      
    zeroFV_iycf <- result[[2]] %>% as.data.frame()
      zeroFV_iycf <- zeroFV_iycf[20:120,]
      zeroFV_iycf <- zeroFV_iycf %>%
        # Remove observations from within the 2019 year
        select(-c(17:18)) 
      colnames(zeroFV_iycf) <- newnames
      zeroFV_iycf <- zeroFV_iycf[2:120,]
      zeroFV_iycf <- zeroFV_iycf %>%
        pivot_longer(2:17, names_to = "year", values_to = "value") %>%
        mutate(indicator = "Zero fruit or vegetable consumption, children 6-23 months",
               unit = "% population, 6-23 months") %>%
        filter(!(is.na(ISO3)))

    childlabor <- result[[3]] %>% as.data.frame()
      childlabor <- childlabor[15:98,]
      col_names <- seq(from = 2012, to = 2022)
      newnames <- c("ISO3", "2010", col_names)
      colnames(childlabor) <- newnames
      childlabor <- childlabor[2:98,]
      childlabor <- childlabor %>%
        pivot_longer(2:13, names_to = "year", values_to = "value") %>%
        mutate(indicator = "% of children 5-17 engaged in child labor",
               unit = "% population 5-17 years") %>%
        filter(!(is.na(ISO3)))

    unicef_data <- rbind(MDD_iycf, zeroFV_iycf, childlabor)
    
    # Add M49 codes and country names
      unicef_data$M49_code <- countrycode::countrycode(unicef_data$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)
      unicef_data$country <- countrycode::countrycode(unicef_data$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA) 
      
    # Organize
      unicef_data <- unicef_data[, col_order]
  
    # Clean up
      rm(result, MDD_iycf, zeroFV_iycf, childlabor, newnames, col_names)
  
    # Save
      saveRDS(unicef_data, file = file.path(data_out, "unicef_data.rds"))

################################################################################

###############################################
#   International Budget Partnership          #
###############################################
          
### Get data from Open Budget Survey links to datasets (need to download every year of historical data separately and append them):
    url <- "https://internationalbudget.org/sites/default/files/2024-05/ibp_full_data_time_series.xlsx"
    destfile <- tempfile ()
    download.file (url, destfile, mode = 'wb')
    result <- readxl::read_excel(destfile)

    openbudget_data <- result %>%
      rename(ISO2 = COUNTRY,
             year = YEAR,
             value = "OPEN_BUDGET_INDEX") %>%
      select(-c(RANK)) %>%
      mutate(indicator = "Open Budget Index Score",
                 unit = "index")
    
    # Clean up
      rm(path, queries, options, result)
        
    # Add country name, ISO and M_49 codes
      openbudget_data$ISO3 <- countrycode::countrycode(openbudget_data$ISO2, origin = 'iso2c', destination = 'iso3c', warn = TRUE, nomatch = NA)
      openbudget_data$M49_code <- countrycode::countrycode(openbudget_data$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)  
      openbudget_data$country <- countrycode::countrycode(openbudget_data$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  

    # Organize
      openbudget_data <- openbudget_data %>% select(-c(ISO2)) 
      openbudget_data <- openbudget_data[, col_order]
      
    # Clean up
      rm(path, queries, options, result)

    # Save    
      saveRDS(openbudget_data, file = file.path(data_out, "openbudget_data.rds"))

################################################################################

###############################################
#   ILOSTAT                                   #
###############################################
        
### Get data from ILOSTAT R package:
    # fetch indicator definitions on ILOSTAT
      toc <- get_ilostat_toc(segment = getOption("ilostat_segment", "indicator"),
                              lang = getOption("ilostat_lang", "en"),
                              search = getOption("ilostat_search", "none"),
                              filters = getOption("ilostat_filter", "none"),
                              fixed = getOption("ilostat_fixed", TRUE))
    
    # Get data  
      unemployment <- get_ilostat("UNE_DEAP_SEX_GEO_RT_A")
      underemployment <- get_ilostat("TRU_DEMP_SEX_AGE_GEO_RT_A")

    # Clean
      unemployment <- unemployment %>%
        # Keep only rural
        filter(classif1 == "GEO_COV_RUR") %>%
        # Keep only total (not disaggregated by sex) %>%
        filter(sex == "SEX_T") %>%
        # Remove unnecessary columns
        select(c(1,6,7)) %>%
        rename(ISO3 = ref_area,
               value = obs_value,
               year = time) %>%
        # Keep only values from 2000 forward
        filter(year >= 2000) %>%
        mutate(indicator = "Unemployment rate, rural")
      
      underemployment <- underemployment %>%
        # Keep only rural
        filter(classif2 == "GEO_COV_RUR",
        # Keep only total (not disaggregated by sex) %>%
               sex == "SEX_T",
        # Keep only total age group 15-64
               classif1 == "AGE_YTHADULT_Y15-64") %>%
        # Remove unnecessary columns
        select(c(1,7,8)) %>%
        rename(ISO3 = ref_area,
               value = obs_value,
               year = time) %>%
        # Keep only values from 2000 forward
        filter(year >= 2000) %>%
        mutate(indicator = "Underemployment rate, rural")
    
    # Combine into one data frame
      ilo_data <- rbind(unemployment, underemployment) %>%
        mutate(unit = "% working age population")
        
    # Add country name, ISO and M_49 codes
      ilo_data$M49_code <- countrycode::countrycode(ilo_data$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)  
      ilo_data$country <- countrycode::countrycode(ilo_data$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
        
    # Organize
      ilo_data <- ilo_data[, col_order]

    # Clean up
      rm(toc, unemployment, underemployment)
 
    # Save 
      saveRDS(ilo_data, file = file.path(data_out, "ilo_data.rds"))

################################################################################

###############################################
#   Varieties of Democracy                    #
###############################################

### Get data from Varieties of Democracy R package
    vdem_codebook <- vdemdata::codebook
    variables <- c("v2x_accountability", "v2x_cspart")
    vdem_data <- vdemdata::vdem %>%
      filter(year>=2000) %>%
      select(c(1:2,4, variables)) %>%
      rename(accountability = v2x_accountability,
             cspart = v2x_cspart,
             country = country_name,
             ISO3 = country_text_id) %>%
      pivot_longer(., 4:5, names_to = "variable") %>%
      mutate(indicator = case_when(variable == "cspart" ~ "Civil society participation index",
                                   variable == "accountability" ~ "V-Dem Accountability index"),
             unit = "index") %>%
      select(-c(variable))
    
    # Fix country names
      vdem_data$country2 <- countrycode::countrycode(vdem_data$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      vdem_data$M49_code <- countrycode::countrycode(vdem_data$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)  
      vdem_data <- vdem_data %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                           TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))

    # Organize
      vdem_data <- vdem_data[, col_order]

    # Clean up
      rm(variables, vdem_codebook, getdata3, get_indicator_data)

    # Save
      saveRDS(vdem_data, file = file.path(data_out, "vdem_data.rds"))
    
################################################################################

###############################################
#   World Bank                                #
###############################################
  
### Get World Bank indicators from wbstats package
    wbindicators <- as.data.frame(wbstats::wbindicators())
    queries = c("GE.EST",
            "NY.GDP.MKTP.CD",
            "SP.POP.TOTL",
            "per_allsp.adq_pop_tot",
            "per_allsp.cov_pop_tot",
            "IT.CEL.SETS.P2",
            "PA.NUS.PRVT.PP")
    result <- lapply(queries, FUN = getwbdata)
    wb_data <- do.call(rbind, result)

    # Clean up
      rm(wbindicators, result, queries)
    
    # Data cleaning
      wb_data <- wb_data %>%
        mutate(indicator = as.factor(indicator))
      wb_data <- wb_data %>%
        select(-c(iso2c, indicatorID)) %>%
        # Convert population to thousands
        mutate(value = case_when(indicator == "Population, total" ~ value/1000,
                                 TRUE ~ value)) %>%
        rename(ISO3 = iso3c,
               year = date) %>%
        mutate(unit = case_when(str_detect(indicator, pattern = "^Government") ~ "index",
                                str_detect(indicator, pattern = "^Adequacy") ~ "% of total welfare of beneficiary households",
                                str_detect(indicator, pattern = "^Coverage") ~ "% of population",
                                str_detect(indicator, pattern = "^GDP") ~ "current US$",
                                str_detect(indicator, pattern = "^Population") ~ "thousands",
                                str_detect(indicator, pattern = "^Mobile") ~ "Number per 100 people",
                                str_detect(indicator, pattern = "^PPP") ~ "LCU per international $")) %>%
        mutate(indicator = case_when(str_detect(indicator, pattern = "^Government") ~ "Government effectiveness index",
                                str_detect(indicator, pattern = "^Adequacy") ~ "Social protection adequacy",
                                str_detect(indicator, pattern = "^Coverage") ~ "Social protection coverage",
                                str_detect(indicator, pattern = "^GDP") ~ "GDP",
                                str_detect(indicator, pattern = "^Population") ~ "Total population",
                                str_detect(indicator, pattern = "^Mobile") ~ "Mobile cellular subscriptions",
                                str_detect(indicator, pattern = "^PPP") ~ "PPP conversion factor, private consumption"))
    
    # Add M49 codes and fix country names
      wb_data$country2 <- countrycode::countrycode(wb_data$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      wb_data$M49_code <- countrycode::countrycode(wb_data$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)  
      wb_data <- wb_data %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                               TRUE ~ country2)) %>%
            select(-c("country")) %>% rename(country = country2) %>%
            filter(!(is.na(ISO3))) %>%
            filter(!(is.na(M49_code)))
        
    # Organize
      wb_data <- wb_data[, col_order]
    
    # Clean up
      rm(wbindicators, queries, result)

    # Save
      saveRDS(wb_data, file = file.path(data_out, "wb_data.rds"))
      
################################################################################

###############################################
#   Manually Downloaded                       #
###############################################
    
### AQUASTAT
    agwaterdraw <- read_excel(file.path(data_in, "AQUASTAT download_March2024.xlsx"),
                                        sheet = "Data")
    agwaterdraw <- agwaterdraw %>%
      select(c(3:7)) %>%
      rename(country = Area,
             indicator = Variable,
             value = Value,
             unit = Unit,
             year = Year) %>%
      filter(year>=2000) %>%
      mutate(unit = "% total renewable")
    
    # Fix country names and get M49 and ISO codes
      agwaterdraw$ISO3 <- countrycode::countrycode(agwaterdraw$country, origin = 'country.name', destination = 'iso3c', warn = TRUE, nomatch = NA)  
      agwaterdraw$M49_code <- countrycode::countrycode(agwaterdraw$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)  
      agwaterdraw$country2 <- countrycode::countrycode(agwaterdraw$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      agwaterdraw <- agwaterdraw %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                       TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))

    # Organize
      agwaterdraw <- agwaterdraw[, col_order]
      saveRDS(agwaterdraw, file = file.path(data_out, "agwaterdraw.rds"))

### FAO - DSFI
    dsfi_kcal <- read_excel(file.path(data_in, "DSFI_2010-2020_CLEAN - Jan.2024.xlsx"),
                                        sheet = "DSFI_2010-2020")
    dsfi_kcal <- dsfi_kcal %>% select(c(1:3)) %>%
      rename(country = area,
             yearrange = year,
             value = DSFIkcal) %>%
      separate(yearrange, c("range_start", "range_end")) %>%
      mutate_at(c("range_start", "range_end"), as.numeric) %>%
      # Assign the value to the midpoint year of the 3-year range
      mutate(year = range_start+1,
             unit = "index",
             indicator = "Dietary sourcing flexibility index") %>%
      select(-c("range_start", "range_end"))
    
    # Fix country names and get M49 and ISO codes
      dsfi_kcal$ISO3 <- countrycode::countrycode(dsfi_kcal$country, origin = 'country.name', destination = 'iso3c', warn = TRUE, nomatch = NA)  
      dsfi_kcal$M49_code <- countrycode::countrycode(dsfi_kcal$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)  
      dsfi_kcal$country2 <- countrycode::countrycode(dsfi_kcal$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)
      dsfi_kcal <- dsfi_kcal %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                       TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))

    # Organize
      dsfi_kcal <- dsfi_kcal[, col_order]
      
    # Save
      saveRDS(dsfi_kcal, file = file.path(data_out, "dsfi_kcal.rds"))
           
### Minderoo Foundation Global Fishing Index
    fishhealth <- read_excel(file.path(data_in, "Global Fishing Index 2021 Data for Download V1.1.xlsx"),
                             sheet = "Progress and Governance results",
                             range = cell_rows(2:143))
    fishhealth <- fishhealth %>%
      select(c(1,2,5)) %>%
      mutate(year = 2021,
             indicator = "Fishery health index progress score",
             unit = "score") %>%
      rename(value = "Progress score",
             ISO3 = "ISO Code")
    
    # Fix country names and get M49 and ISO codes
      fishhealth$M49_code <- countrycode::countrycode(fishhealth$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)  
      fishhealth$country2 <- countrycode::countrycode(fishhealth$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      fishhealth <- fishhealth %>% mutate(country2 = case_when(is.na(country2) ~ Country,
                                                     TRUE ~ country2)) %>%
        select(-c("Country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))

    # Organize
      fishhealth <- fishhealth[, col_order]
    
    # Save
      saveRDS(fishhealth, file = file.path(data_out, "fishhealth.rds"))
  
### IHR Food safety capacity
    foodsafety <- read_csv(file.path(data_in, "IHR SPAR_14Mar2024.csv"))
    foodsafety <- foodsafety %>% 
      select(c(2,7,8,10,30))
    cols <- c("indicator", "ISO3", "country", "year", "value")
    colnames(foodsafety) <- cols
    foodsafety <- foodsafety %>% 
      mutate(indicator = "Food safety capacity",
             unit = "score")
     
    # Fix country names and get M49 and ISO codes
      foodsafety$M49_code <- countrycode::countrycode(foodsafety$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)  
      foodsafety$country2 <- countrycode::countrycode(foodsafety$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      foodsafety <- foodsafety %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                       TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))
    
    # Organize
      foodsafety <- foodsafety[, col_order]

    # Clean up
      rm(cols)
    
    # Save
      saveRDS(foodsafety, file = file.path(data_out, "foodsafety.rds"))
    
### Euromonitor retail value of ultraprocessed foods
    upfretailval <- read_excel(file.path(data_in, "UPFretailval.xlsx"))
    upfretailval <- upfretailval %>%
      pivot_longer(2:6, names_to = "year", values_to = "value") %>%
      rename(country = Country) %>%
      mutate(unit = "current (nominal) US$/year",
             indicator = "Retail value of ultra-processed foods per capita")
  
    # Add M49 codes and fix country names
      upfretailval$ISO3 <- countrycode::countrycode(upfretailval$country, origin = 'country.name', destination = 'iso3c', warn = TRUE, nomatch = NA)  
      upfretailval$M49_code <- countrycode::countrycode(upfretailval$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)  
      upfretailval$country2 <- countrycode::countrycode(upfretailval$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      upfretailval <- upfretailval %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                       TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))
  
    # Organize
      upfretailval <- upfretailval[, col_order]
        
    # Now convert to PPP dollars
      PPP <- wb_data %>%
        filter(indicator == "PPP conversion factor, private consumption") %>%
        rename(PPP_factor = value) %>%
        select(-c(indicator, unit))
      upfretailval <- left_join(upfretailval, PPP, by = c("country", "ISO3", "M49_code", "year"))
      upfretailval <- upfretailval %>%
        mutate(value = value/PPP_factor,
               unit = "current PPP US$/year") %>%
        select(-c(PPP_factor))

    # Clean up
      rm(PPP)
    
    # Save
      saveRDS(upfretailval, file = file.path(data_out, "upfretailval.rds"))
               
### WFP coping strategies
    sheets <- c("2020", "2021", "2022", "2023")
    result <- lapply(sheets, function(x) read_excel(file.path(data_in, "HMU_rcsi.xlsx"),
                                        sheet = x))
    rcsi <- do.call(rbind, result)

    # Data cleaning
      rcsi <- rcsi %>% 
        select(-c(6,7)) %>%
        rename(ISO3 = country,
               country = country_name,
               value = rcsi_prevalence)
    
    # Add M49 codes and fix country names
      rcsi$M49_code <- countrycode::countrycode(rcsi$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA)  
      rcsi$country2 <- countrycode::countrycode(rcsi$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      rcsi <- rcsi %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                       TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))
    
    # Identify annual maximum observed prevalence per country-year
      rcsi <- rcsi %>%
        filter(!(is.na(value))) %>%
        group_by(country, year) %>%
        mutate(maxprevalence = max(value, na.rm = TRUE)) %>%
        ungroup()
      rcsi <- rcsi %>% select(c(3:4,6:8)) %>%
        unique() %>%
        rename(value = maxprevalence)  %>%
        mutate(indicator = "Prevalence of severe coping strategies",
               unit = "% population")
        
    # Organize
      rcsi <- rcsi[, col_order]
  
    # Clean up
      rm(sheets, result)
    
    # Save
      saveRDS(rcsi, file = file.path(data_out, "rcsi.rds"))
        
### Presence of a food system pathway
    fspathway <- read.csv(file.path(data_in, "FSPathways_Mar2024.csv"))
    fspathway <- fspathway %>%
      mutate(value = 1,
             indicator = "Presence of a national food system transformation pathway",
             unit = "binary",
             year = 2022) %>%
      rename(country = Country) %>%
      select(c(country, value, indicator, unit, year))
    
    # Now add the 2023 data
      fspathway_2023 <- read.csv(file.path(data_in, "FS Pathway_Countries_2023.csv"))
      fspathway_2023 <- fspathway_2023 %>%
        select(c(Country)) %>%
        mutate(value = 1,
               indicator = "Presence of a national food system transformation pathway",
               unit = "binary",
               year = 2024) %>%
        rename(country = Country) %>%
        select(c(country, value, indicator, unit, year))   
      
    # Bind rows
      fspathway <- rbind(fspathway, fspathway_2023)
  
    # Add M49 codes and fix country names
      fspathway$ISO3 <- countrycode::countrycode(fspathway$country, origin = 'country.name', destination = 'iso3c', warn = TRUE, nomatch = NA) 
      fspathway$M49_code <- countrycode::countrycode(fspathway$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
      fspathway$country2 <- countrycode::countrycode(fspathway$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      fspathway <- fspathway %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                       TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))
     
    # Organize
      fspathway <- fspathway[, col_order]
    
    # Clean up
      rm(fspathway_2023)
    
    # Save
      saveRDS(fspathway, file = file.path(data_out, "fspathway.rds"))

### Social capital - Legatum prosperity data
    socialcap <- readxl::read_excel(file.path(data_in, "2021_Full_Data_Set_-_Legatum_Prosperity_Index.xlsx"),
                                    sheet = "Indicators x 300")
    socialcap <- socialcap %>% 
      mutate_at(c("pillar_name", "element_name", "indicator_name"), as.factor) %>%
      filter(pillar_name == "Social Capital") %>%
      # keep score only
      select(-c(7:36))
    levels(socialcap$indicator_name)
    tokeep <- c("Help from family and friends when in trouble",
                "Generalised interpersonal trust",
                "Confidence in financial institutions and banks",
                "Public trust in politicians")
    socialcap <- socialcap %>%
      filter(indicator_name %in% tokeep) %>%
      select(c(1:2,6:21)) %>%
      pivot_longer(4:18, names_to = "year", 
                   values_to = "score") %>%
      mutate_at("year", str_replace, "score_", "") %>%
      mutate(year = as.numeric(year)) %>%
      rename(country = area_name, 
             ISO3 = area_code)
    
    # Now calculate the social capital as the geometric mean of remaining 4 indicators by country-year
      socialcap <- socialcap %>%
        arrange(country, year) %>%
        group_by(country, year) %>%
        mutate(socialcapital = exp(mean(log(score)))) %>%
        ungroup() 
    
    # Data cleaning
      socialcap <- socialcap %>%
        select(-c(indicator_name, score)) %>%
        unique() %>%
        rename(value = socialcapital) %>%
        mutate(indicator = "Social capital index",
               unit = "index")
    
    # Add M49 codes and fix country names
      socialcap$ISO3 <- countrycode::countrycode(socialcap$country, origin = 'country.name', destination = 'iso3c', warn = TRUE, nomatch = NA) 
      socialcap$M49_code <- countrycode::countrycode(socialcap$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
      socialcap$country2 <- countrycode::countrycode(socialcap$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      socialcap <- socialcap %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                       TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))
    
    # Organize
      socialcap <- socialcap[, col_order]
    
    # Clean up
      rm(tokeep)
    
    # Save
      saveRDS(socialcap, file = file.path(data_out, "socialcap.rds"))

### Functional integrity
    
    # First import the data used previously in 2023 paper, with only 10% threshold for the year 2015
      funcinteg_10pct <- read.csv(file.path(data_in, "Apex2021_FullTable_GAUL.csv"))
      funcinteg_10pct <- funcinteg_10pct %>%
        select(c(1,8)) %>%
        rename(country = ADM0_NAME,
               value = Integ1km10) %>%
        mutate(year = 2015,
               indicator = "Functional integrity: agricultural land with minimum level of natural habitat - 10% threshold",
               unit = "% agricultural land")
    
    # Add M49 codes and fix country names
      funcinteg_10pct$ISO3 <- countrycode::countrycode(funcinteg_10pct$country, origin = 'country.name', destination = 'iso3c', warn = TRUE, nomatch = NA) 
      funcinteg_10pct$M49_code <- countrycode::countrycode(funcinteg_10pct$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
      funcinteg_10pct$country2 <- countrycode::countrycode(funcinteg_10pct$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      funcinteg_10pct <- funcinteg_10pct %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                       TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))
    
    # Organize
      funcinteg_10pct <- funcinteg_10pct[, col_order]
    
    # Save this historical series in the tidied format
      saveRDS(funcinteg_10pct, file = file.path(data_in, "functionalintegrity_10pct_2015.rds"))
    
    # Clean up
      rm(funcinteg_10pct)
      
  # Now bring in the revised 2015 data with the 20% threshold
    funcinteg <- read_excel(file.path(data_in, "FSCI_ESA2015_20_edited.xlsx"))
    funcinteg1 <- funcinteg %>%
      select(c(5,6,10)) %>%
      rename(country = ADM0_NAME...5,
             value = "Integrity",
             ISO3 = Iso3_Code) %>%
      mutate(year = 2015,
             indicator = "Functional integrity: agricultural land with minimum level of natural habitat",
             unit = "% agricultural land")
    agland_ESA <- funcinteg %>%
      select(c(5,6,11)) %>%
      rename(country = ADM0_NAME...5,
             value = "Area_m2_Ag",
             ISO3 = Iso3_Code) %>%
      mutate(year = 2015,
             indicator = "Agricultural land area - ESA",
             unit = "sq meters")
    funcinteg <- rbind(funcinteg1, agland_ESA)
    funcinteg <- funcinteg %>%
      filter(!(country == "India" & indicator == "Agricultural land area - ESA" & value == 0))
    
    # Add M49 codes and fix country names
      funcinteg$ISO3 <- countrycode::countrycode(funcinteg$country, origin = 'country.name', destination = 'iso3c', warn = TRUE, nomatch = NA) 
      funcinteg$M49_code <- countrycode::countrycode(funcinteg$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
      funcinteg$country2 <- countrycode::countrycode(funcinteg$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      funcinteg <- funcinteg %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                       TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))
    
    # Organize
      funcinteg <- funcinteg[, col_order]
    
    # Clean up
      rm(funcinteg1, agland_ESA)
      
    # Save
      saveRDS(funcinteg, file = file.path(data_out, "funcinteg.rds"))
    
```


$~$

Now we create the variables that we have developed or modify.

$~$

Ratio of all disasters to GDP

```{r, warning = FALSE, messages = FALSE}
### Import Em-DAT disaster data
    emdat <- readxl::read_excel(file.path(data_in, "public_emdat_2024-03-14.xlsx"),
                                    sheet = "EM-DAT Data")
    emdat <- emdat %>%
      select(c(10:11,26,41)) 
    cols <- c("ISO3", "country", "year", "damages")
    colnames(emdat) <- cols
    # Sum to the annual level
    emdat <- emdat %>%
      filter(!(is.na(damages))) %>%
      arrange(country, year) %>%
      group_by(country, year) %>%
      mutate(annual_cost = sum(damages)) %>%
      ungroup() %>%
      select(-c(damages)) %>%
      unique()
  
    # Add M49 codes and fix country names
      emdat$M49_code <- countrycode::countrycode(emdat$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
      emdat$country2 <- countrycode::countrycode(emdat$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      emdat <- emdat %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                       TRUE ~ country2)) %>%
        select(-c("country")) %>% rename(country = country2) %>%
        filter(!(is.na(ISO3)))
  
    # Join with GDP data
      GDP <- wb_data %>% filter(indicator == "GDP") %>%
        mutate(year = as.numeric(year)) %>%
        rename(GDP = value) %>%
        select(c("country", "ISO3", "M49_code", "year", "GDP"))
      emdat <- left_join(emdat, GDP, by = c("country", "ISO3", "M49_code", "year"))
      emdat <- emdat %>%
        mutate(value = (annual_cost/GDP)*100,
               indicator = "Ratio of total damages from all disasters to GDP",
               unit = "ratio") %>%
        select(-c(annual_cost, GDP))
    
    # Organize
      emdat <- emdat[, col_order]
        
    # Clean up
      rm(GDP, cols)
      
    # Save
      saveRDS(emdat, file = file.path(data_out, "emdat.rds"))
  
```

$~$

Agricultural land with minimum species richness

First we need to bring in the 2010 data.
```{r, warning = FALSE, messages = FALSE}
### Import the pixel count data exported from QGIS 
    # Note: HISTO_ variables denote distribution of no of pixels (1 pixel = 10x10km or 10,000 ha) for species count 1-38) within each country
    # HISTO_NODATA = non-agricultural land
      minspecies <- read.csv(file.path(data_in, "global.hist.tsr.csv"))
      minspecies <- minspecies %>%
        select(4,6,9:47) %>%
        mutate(pixelsTotal = rowSums(.[4:41]))
    
    # Collapse the dataset to the global level to find the threshold number of species at which (and above) covers 25% of global ag land (the 25% of land with the most diversity)
      minspecies_global <- minspecies %>%
        select(-c(1:3)) %>%
        summarise_all(.funs = sum) %>%
        pivot_longer(1:38, names_to = "n_species", values_to = "n_pixels") %>%
        mutate(n_species = str_replace(n_species, "HISTO_",""),
               n_species = as.numeric(n_species)) %>%
        relocate(pixelsTotal, .after = n_pixels) %>%
        mutate(share = (n_pixels / pixelsTotal),
               cum_sum = cumsum(share))
      minspecies_threshold <- minspecies_global %>%
        filter(cum_sum > 0.75) %>%
        mutate(idvar = case_when(cum_sum == min(cum_sum) ~ 1,
                                 TRUE ~ NA))
      minspecies_threshold %>% filter(idvar == 1) %>%
        select(n_species) %>%
        print()
  
    # Now add up the number of pixels per country at or above 24 species as a % of the total
      minspecies <- minspecies %>%
        select(-c(3:26)) %>%
        # Filter out areas with zero agricultural land (pixelsTotal == 0)
        filter(!(pixelsTotal==0)) %>%
        mutate(richness_sum = rowSums(.[3:17]),
               pctagland_minspecies = (richness_sum / pixelsTotal)*100) %>%
        select(1,18,20) %>%
        rename(ISO3 = iso3,
               agland_minspecies = pixelsTotal) %>%
        pivot_longer(2:3, names_to = c("indicator"),
                     values_to = c("value")) %>%
        mutate(unit = case_when(indicator == "pctagland_minspecies" ~ "% agricultural land",
                                     indicator == "agland_minspecies" ~ "pixels"),
               indicator = case_when(indicator == "pctagland_minspecies" ~ "Proportion of agricultural land with minimum level of species diversity (crop and pasture)",
                                     indicator == "agland_minspecies" ~ "Agricultural land area - Minimum species richness"),
               year = 2010) %>%
        filter(!(is.na(ISO3)))
      
    # Add M49 codes and fix country names
      minspecies$M49_code <- countrycode::countrycode(minspecies$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
      minspecies$country <- countrycode::countrycode(minspecies$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      # Filter non-UN-member states (have no country name)
      minspecies <- minspecies %>% filter(!(is.na(country))) 

    # Organize
      minspecies_2010 <- minspecies[, col_order]
            
    # Clean up
      rm(minspecies_global, minspecies_threshold, minspecies)
      
    # Save
      saveRDS(minspecies_2010, file = file.path(data_out, "minspecies_2010.rds"))

```

$~$

Now we add the 2020 data.
```{r, warning = FALSE, messages = FALSE}
### Manually downloaded data layers from MapSPAM and the Global Gridded Livestock data

    # From each of the two data sources (MapSPAM and Global Gridded Livestock product):
    # keep only the spam files ending in "A" and only the .tif file format livestock files ending in "Da")
    # Put/find these files in a subfolder called "Minimum species richness"
    # List all files in the directory with the abundance layers (assuming .tif format)
      layer_files <- list.files(path = file.path(data_in, "Min species richness layers"), 
                                pattern="*.tif$", full.names=TRUE)

    # Define a functino to process the .tif layers
      process_layer <- function(file) {
        
        # Read the raster layer
        species <- terra::rast(file)
        
        # Replace NA values with 0 (species not present)
        species[is.na(species)] <- 0
        
        # Replace non-zero values with 1 (species present)
        species[species > 0] <- 1
        
        # Return the layer with processed abundance data
        return(species)
      }
    
    
    # Read and process each layer using the defined function
      processed_layers <- lapply(layer_files, process_layer)
    
    # Stack all processed layers into a single brick object
      species_stack <- terra::rast(processed_layers)
    
    # Calculate species richness by summing across all layers
      species_richness <- sum(species_stack)
      
    # Estimating threshold (minimum richness)
      # Create data frame for calculation, only considering cells with at least 1 species
        richness_aux  <- terra::clamp(species_richness, lower=1, value=FALSE)
  
      # Estimate quantiles
        qr <- terra::global(richness_aux, quantile, na.rm=TRUE)
      
      # Define cut off point for minimum species richness as 75% quantile of global agricultural land species richness (threshold of the 25th percentile of the most diverse land)
        threshold <- qr$X75.
    
    # Identifying cells with minimum richness   
      # Create new layer
        min_species <- species_richness
      
      # Create matrix with max and min values for richness
        extremes <- terra::minmax(species_richness)
    
      #Create reclassification matrix
        m <- c(0, threshold, 0,
               threshold, extremes[2,],1) 
             
        rclmat <- matrix(m, ncol=3, byrow=TRUE)
    
      # Assign 1 for pixels with more species than the threshold, and 0 for those with fewer species.
        min_species <- terra::classify(min_species, rclmat, include.lowest=TRUE)
      
      # Write a raster that shows if each cell has the minimum number of species (1) or not (0)
        terra::writeRaster(min_species, filename=file.path(data_out,"min_species.tif"), overwrite=TRUE)

    # Assign countries to cells 
      #Read country boundaries
        #Note: requires all files of the name "world-administrative-boundaries" that come in the zip file on manual download with different format extensions
        countries <- terra::vect(file.path(data_in, "world-administrative-boundaries.shp"))
        
        # Extract country iso3 codes to a data frame
          iso3_codes <- data.frame(countries$iso3)
        
        # Count how many cells in each country have the minimum number of species
          pixels_min_species_per_country <- terra::zonal(min_species, countries, sum)
        
        # Identify total number of agricultural land cells per country 
        # if there is at least one species, it is ag land
          ag_land <- species_richness
          ag_land[ag_land > 0] <- 1
        
        # Add all pixels in each country to get the count
          # This is the total agricultural land consistent with this indicator
          # This should be used as the indicator of agland used to create weighted means
            agland_SPAM_GLW <- terra::zonal(ag_land, countries, sum)
        
        # Estimate proportion of cells with minimum species richness
          proportion_per_country <- cbind(iso3_codes, agland_SPAM_GLW, pixels_min_species_per_country)
          colnames(proportion_per_country) <- c("iso3", "ag_land", "min_species")
          
        # Drop territories with no ISO3 code
          proportion_per_country <- proportion_per_country %>%
            filter(!(is.na(iso3)))
          
        # Drop areas with no agricultural land
          proportion_per_country <- proportion_per_country %>%
            filter(!(ag_land == 0))
          
        # Calculate proportion of pixels per country with minimum richness
          proportion_per_country <- proportion_per_country %>% 
            dplyr::mutate(proportion_ag_land_with_min_sp = (min_species/ag_land)*100)

        # Create data frame and harmonize
          minspecies_2020 <- dplyr::select(proportion_per_country, -c(min_species))
          minspecies_2020 <- minspecies_2020 %>%
            pivot_longer(2:3, names_to = c("indicator"), values_to = c("value")) %>%
            mutate(unit = case_when(indicator == "proportion_ag_land_with_min_sp" ~ "% agricultural land",
                                         indicator == "ag_land" ~ "pixels"),
                   indicator = case_when(indicator == "proportion_ag_land_with_min_sp" ~ "Proportion of agricultural land with minimum level of species diversity (crop and pasture)",
                                         indicator == "ag_land" ~ "Agricultural land area - Minimum species richness"),
                   year = 2020) %>%
            rename(ISO3 = iso3)
          
    # Add M49 code and country names
      minspecies_2020$M49_code <- countrycode::countrycode(minspecies_2020$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
      minspecies_2020$country <- countrycode::countrycode(minspecies_2020$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
      # Drop ISO3 codes with no UN country name - indicates it is a territory
        minspecies_2020 <- minspecies_2020 %>% 
          filter(!(is.na(country)))
            
    # Organize
      minspecies_2020 <- minspecies_2020[, col_order]
        
            
    # Clean up
      rm(proportion_per_country, pixels_min_species_per_country, ag_land, agland_SPAM_GLW, species_richness, min_species, iso3_codes, processed_layers, species_stack, layer_files, process_layer, m, rclmat, extremes, richness_aux, qr, countries)
    
    # Save
      saveRDS(minspecies_2020, file = file.path(data_out, "minspecies_2020.rds"))

```
    
$~$

Presence of any health-related food environment policies

```{r, warning = FALSE, messages = FALSE}
# Import the full NOURISHING database
  foodenviropol <- read.csv(file.path(data_in, "policy-export22-Mar-2024.csv"))
    
# Classification
  foodenviropol$Policy.area <- as.factor(foodenviropol$Policy.area)
  levels(foodenviropol$Policy.area)
    
  # Keep food environment policy areas only
  food_enviro <- c("Nutrition label standards and regulations on the use of claims and implied claims on food",
                   "Offer healthy food and set standards in public institutions and other specific settings",
                   "Use economic tools to address food affordability and purchase incentives",
                   "Restrict food advertising and other forms of commercial promotion",
                   "Improve nutritional quality of the whole food supply",
                   "Set incentives and rules to create a healthy retail and food service environment")
  
  # Classify status as mandatory or voluntary, includes specific text strings identified through iterative manual review of the policy action field until no records were left unclassified
  foodenviropol <- foodenviropol %>%
    filter(Policy.area %in% food_enviro)

    foodenviropol <- foodenviropol %>%
      mutate(type = case_when(Policy.area == "Nutrition label standards and regulations on the use of claims and implied claims on food" ~ "regulatory",
                              Policy.area == "Offer healthy food and set standards in public institutions and other specific settings" ~ "regulatory",
                              Policy.area == "Use economic tools to address food affordability and purchase incentives" ~ "economic",
                              Policy.area == "Restrict food advertising and other forms of commercial promotion" ~ "regulatory",
                              Policy.area == "Improve nutritional quality of the whole food supply" ~ "regulatory",
                              Policy.area == "Set incentives and rules to create a healthy retail and food service environment" ~ "regulatory")) %>%
      mutate(status = case_when(str_detect(Sub.policy.area, regex('mandatory', ignore_case = T)) ~ "mandatory",
                                   str_detect(Sub.policy.area, regex('voluntary', ignore_case = T)) ~ "voluntary",
                              type == "economic" ~ "mandatory",
                              TRUE ~ "")) %>%
      mutate(status = case_when(str_detect(Policy.action, regex('mandator*', ignore_case = T)) & status == "" ~ "mandatory",    
                              str_detect(Policy.action, regex('compuls*', ignore_case = T)) & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('law', ignore_case = T)) & status == "" ~ "mandatory",
                              str_detect(Policy.action, 'Act') ~ "mandatory",
                              str_detect(Policy.action, regex('legislat*', ignore_case = T)) & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('Regulation*')) & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('EU-wide rules', ignore_case = T)) & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('ban', ignore_case = T)) & status == "" ~ "mandatory",
                              #str_detect(Policy.action, regex('standards', ignore_case = T)) & status == "" ~ "mandatory",
                              #str_detect(Policy.action, regex('rules', ignore_case = T)) & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('voluntar*', ignore_case = T)) & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('guideline*', ignore_case = T)) & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('guidance*', ignore_case = T)) & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('recommend*', ignore_case = T)) & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('award*', ignore_case = T)) & status == "" ~ "voluntary",
                              Sub.policy.area == "Bans specific to vending machines in schools" & status == "" ~ "mandatory",
                              Sub.policy.area == 'Clearly visible "interpretative" labels and warning labels' & status == "" ~ "mandatory",
                              Sub.policy.area == "Government engage with industry to develop self-regulation to restrict food marketing to children" & Country == "UK" & status == "" ~ "mandatory",
                              Sub.policy.area == "Warning labels on menus and displays in out-of-home venues" & Country == "South Korea" & status == "" ~ "voluntary",
                              Sub.policy.area == "Standards in social support programmes" & Country == "Mexico" & status == "" & str_detect(Policy.action, regex('Subsidised milk', ignore_case = T)) ~ "voluntary",
                              str_detect(Policy.action, regex('memorandum of', ignore_case = T)) & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('discretion of local authorities', ignore_case = T)) & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('participating schools', ignore_case = T)) & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('The Food Labelling Guide', ignore_case = T)) & Country == "USA" & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('The Northern Fruit and Vegetable Program', ignore_case = T)) & Country == "Canada" & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('Manitoba', ignore_case = T)) & Sub.policy.area == "Fruit & vegetable initiatives in schools" & Country == "Canada" & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('British Columbia', ignore_case = T)) & Sub.policy.area == "Fruit & vegetable initiatives in schools" & Country == "Canada" & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('Healthier vending policy', ignore_case = T)) & Country == "Ireland" & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('ORDIN Nr. 25/2019', ignore_case = T)) & Country == "Romania" & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('The National Prevention act', ignore_case = T)) & Country == "Netherlands" & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('Healthy Eating in Higher Education', ignore_case = T)) & Country == "Portugal" & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('SGF Healthy Living Programme', ignore_case = T)) & Country == "UK" & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('Nutrition, Health and Related Claims Standard 1.2.7', ignore_case = T)) & (Country == "Australia" | Country == "New Zealand") & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('Crunch&amp;Sip', ignore_case = T)) & Country == "Australia" & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('Nutrition standards in hospitals', ignore_case = T)) & Country == "Croatia" & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('Health protection requirements', ignore_case = T)) & Country == "Estonia" & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('Standards on level of fat in meat', ignore_case = T)) & Country == "Ghana" & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('Salt levels limits for food served in hospitals', ignore_case = T)) & Country == "Latvia" & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('Salt levels limits for food served in hospitals', ignore_case = T)) & Country == "Latvia" & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('Swiss quality standards', ignore_case = T)) & Country == "Switzerland" & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('School Fruit and Vegetable Scheme', ignore_case = T)) & Country == "UK" & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('Santa Clara|California USA|Berkeley|Davis|Stockton|Perris', ignore_case = T)) & Country == "USA" & status == "" ~ "voluntary",
                              str_detect(Policy.action, regex('San Francisco|NYC|WIC|Detroit', ignore_case = T)) & Country == "USA" & status == "" ~ "mandatory",
                              str_detect(Policy.action, regex('at*discretion of', ignore_case = T)) ~ "voluntary",
                              TRUE ~ status))

  # Identify and eliminate subnational policies
  foodenviropol <- foodenviropol %>%
    mutate(national = case_when(str_detect(Policy.action, regex('local level|subnational', ignore_case = T)) & (!(str_detect(Policy.action, regex('EU|national', ignore_case = T)))) ~ "subnational",
                                str_detect(Policy.action, regex('San Francisco|NYC|New York City|Philadelphia|Detroit|Boston|Puerto Rico|Maine|Santa Clara|Berkeley|Davis|Stockton|Perris|California|Seattle|Oakland|Boulder|Albany|Navajo Nation|Cook County|Massachusetts|San Bernadino|Arkansas', ignore_case = T)) & Country == "USA" ~ "subnational",
                                str_detect(Policy.action, regex('Crunch&amp;Sip', ignore_case = T)) & Country == "Australia" ~ "subnational",
                                str_detect(Policy.action, regex('local health district|Queensland|Western district|New South Wales', ignore_case = T)) & Country == "Australia" ~ "subnational",
                                str_detect(Policy.action, regex('Belgium (French region)', ignore_case = T)) & Country == "Belgium" ~ "subnational",
                                str_detect(Policy.action, regex('Ontario|British Columbia|Manitoba|North Canada', ignore_case = T)) & Country == "Canada" ~ "subnational",
                                str_detect(Policy.action, regex('Cook Islands', ignore_case = T)) & Country == "New Zealand" ~ "subnational",
                                str_detect(Policy.action, regex('Catalonia', ignore_case = T)) & Country == "Spain" ~ "subnational",
                                Country == "Taiwan" ~ "subnational",
                                str_detect(Policy.action, regex('Abu Dhabi', ignore_case = T)) & Country == "UAE" ~ "subnational",
                                str_detect(Policy.action, regex('Brighton|England|Scotland|Wales|Northern Ireland', ignore_case = T)) & Country == "UK" ~ "subnational",
                                TRUE ~ "national"))
          
  # Data cleaning
  foodenviropol <- foodenviropol %>%
    mutate(Country = case_when(str_detect(Policy.action, regex('Nauru', ignore_case = T)) ~ "Nauru",
                               str_detect(Policy.action, regex('Palau', ignore_case = T)) ~ "Palau",
                               Country == "Taiwan" ~ "China",
                               TRUE ~ Country))
  
  # Country names and codes
  foodenviropol$ISO3 <- countrycode::countrycode(foodenviropol$Country, origin = 'country.name', destination = 'iso3c', warn = TRUE, nomatch = NA)  
  foodenviropol$M49_code <- countrycode::countrycode(foodenviropol$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
  foodenviropol$country2 <- countrycode::countrycode(foodenviropol$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
  foodenviropol <- foodenviropol %>% mutate(country2 = case_when(is.na(country2) ~ Country,
                                                   TRUE ~ country2)) %>%
    select(-c("Country")) %>% rename(country = country2) %>%
    filter(!(is.na(ISO3)))
  
  # Export classification
  write.csv(foodenviropol, file.path(data_out, "Food environment policies classification.csv"))
  
  # Create the final indicator
  foodenviropol <- foodenviropol %>%
    select(-c(1:5)) %>%
    mutate(across(1:3, as.factor)) %>%
    filter(national == "national" & status == "mandatory") %>%
    unique() %>%
    select(-c(national, status)) %>%
    mutate(value = 1) %>%
    relocate(value, .after = type) %>%
    pivot_wider(id_cols = c("country", "ISO3", "M49_code"), names_from = "type", values_from = "value") %>%
    mutate(both = rowSums(across(4:5), na.rm = TRUE),
           both = case_when(both == 1 ~ NA,
                            both == 2 ~ 1),
           regulatory = case_when(both == 1 ~ NA,
                                  TRUE ~ regulatory),
           economic = case_when(both == 1 ~ NA,
                                  TRUE ~ economic))
  
  foodenviropol <- foodenviropol %>%
    mutate(value = case_when(regulatory == 1 ~ "regulatory",
                             economic == 1 ~ "economic",
                             both == 1 ~ "both"),
           indicator = "Presence of national health-related food environment policies",
           unit = "categorical",
           year = 2023) %>%
    select(-c(4:6))

# Organize
  foodenviropol <- foodenviropol[, col_order]
  saveRDS(foodenviropol, file = file.path(data_out, "foodenviropol.rds"))
 
```

$~$

Get the 2021 Right to food data

```{r, warning = FALSE, messages = FALSE}
# Import the dataset from the 2023 baseline paper
  rtf_2021 <- read.csv(file.path(data_in, "righttofood_2021.csv"))

# Establish the categories
  rtfcategories <- c("Explicit protection of the right to food or directive of state policy","Some other implicit recognition, codification of international statutes, or other pertinent provisions", "None")
  rtf_2021 <- rtf_2021 %>%
    select(c(1:3,9,16)) %>%
    rename(ISO3 = ISO,
           M49_code = m49_code,
           value = righttofood) %>%
    mutate(unit = "categorical",
           indicator = "Degree of legal recognition of the Right to Food",
           year = 2021)
  rtf_2021$value <- factor(rtf_2021$value, levels = 1:3, labels = rtfcategories)
  
# Add M49 codes and fix country names
  rtf_2021$country2 <- countrycode::countrycode(rtf_2021$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
  rtf_2021 <- rtf_2021 %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                   TRUE ~ country2)) %>%
    select(-c("country")) %>% rename(country = country2) %>%
    filter(!(is.na(ISO3)))

# Organize
  rtf_2021 <- rtf_2021[, col_order]
```

$~$

Right to food - 2024

```{r, warning = FALSE, messages = FALSE}
# Import dataset created by reviewing https://www.fao.org/right-to-food-around-the-globe/constitutional-level-of-recognition/en/
  rtf <- readxl::read_excel(file.path(data_in, "Rigth-to-Food_Dataset_2024.xlsx"),
                                  sheet = "Sheet1")
  rtf <- rtf %>% select(-c(3)) %>%
    mutate(value = as.factor(degree_of_recognition)) %>%
    select(-c(degree_of_recognition)) %>%
    mutate(year = 2024,
           indicator = "Degree of legal recognition of the Right to Food",
           unit = "categorical")
  
  # Classify into 3 categories so that there is one value per country per year:
    # Explicit protection of the right to food or directive of state policy
    # Some other implicit recognition, codification of international statues, or other pertinent provisions
    # None
  
  # Identify the highest level of recognition so there is one value per country-year
  rtf2 <- rtf %>% 
    mutate(valtemp = 1) %>%
    pivot_wider(names_from = value, values_from = valtemp) %>%
    mutate(value_select = "",
           value_select = case_when((`Explicit protection of the right to adequate food` == 1 | `Directive principles of state policy` == 1) ~ "Explicit protection of the right to adequate food",
                                    value_select == "" & (`National status of international obligations` == 1 | `Other pertinent provisions for the realization of the right to adequate food` == 1) ~ "Some other implicit recognition, codification of international statues, or other pertinent provisions",
                                    value_select == "" ~ "None",
                                    TRUE ~ value_select))
  rtf2 <- rtf2 %>% select(c(country, year, value_select))
  rtf <- left_join(rtf, rtf2, by = c("country", "year"))
  rtf <- rtf %>%
    select(-c(value)) %>%
    unique() %>%
    rename(value = value_select)
  rtf$value <- factor(rtf$value, levels = 1:3, labels = rtfcategories)
  

# Add ISO3 & M49 codes and fix country names
  rtf$ISO3 <- countrycode::countrycode(rtf$country, origin = 'country.name', destination = 'iso3c', warn = TRUE, nomatch = NA)  
  rtf$M49_code <- countrycode::countrycode(rtf$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
  rtf$country2 <- countrycode::countrycode(rtf$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
  rtf <- rtf %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                   TRUE ~ country2)) %>%
    select(-c("country")) %>% rename(country = country2) %>%
    filter(!(is.na(ISO3)))

# Organize
  rtf_2024 <- rtf[, col_order]
  rtf <- rbind(rtf_2021, rtf_2024)

# Clean up
  rm(rtf_2024, rtf_2021, rtf2, rtfcategories)
  saveRDS(rtf, file = file.path(data_out, "rtf.rds"))
       
```

$~$

Percent of urban population living in a city that has signed onto the Milan Urban Food Policy Pact. First get 2020 data.
```{r, warning = FALSE, messages = FALSE}
# Get 2020 data
  mufpp_2020 <- read.csv(file.path(data_in, "mufpp_pop_2020.csv"))
  mufpp_2020 <- mufpp_2020 %>%
    select(c(1:2,5:6,9)) %>%
    rename(ISO3 = ISO) %>%
    pivot_longer(4:5, names_to = "indicator", values_to = "value") %>%
    mutate(unit = case_when(indicator == "mufppurbshare" ~ "% urban population",
                                 indicator == "pop_u" ~ "thousands"),
           indicator = case_when(indicator == "mufppurbshare" ~ "% urban population living in cities signed onto the Milan Urban Food Policy Pact",
                                 indicator == "pop_u" ~ "Urban population"),
           year = 2020)
  
  # Add M49 codes and fix country names
  mufpp_2020$M49_code <- countrycode::countrycode(mufpp_2020$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
  mufpp_2020$country2 <- countrycode::countrycode(mufpp_2020$ISO3, origin = 'iso3c', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
  mufpp_2020 <- mufpp_2020 %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                   TRUE ~ country2)) %>%
    select(-c("country")) %>% rename(country = country2) %>%
    filter(!(is.na(ISO3)))

# Organize
  mufpp_2020 <- mufpp_2020[, col_order]
  saveRDS(mufpp_2020, file = file.path(data_out, "mufpp_2020.rds"))

```

$~$

Now calculate updated data for 2023 (latest Landscan population data available are 2022, but the city list was updated Jan 2024).
```{r, warning = FALSE, messages = FALSE}
# Make sure S2 is turned on
  sf::sf_use_s2(TRUE)

# Calculate urban & total pop for all countries with signatories cities ####
  # Import list of cities and create data frame of cities and a data frame to identify changes (for hard coding city extracts below)
    # 2021 list
      mufpp_cities_2021 <- readxl::read_excel(file.path(data_in, "MUFPP city data_2021.xlsx")) %>%
        as.data.frame()
      mufpp_cities_2021 <- mufpp_cities_2021[ ,2:1]
    
    # 2024 list
      mufpp_cities <- readxl::read_excel(file.path(data_in, "MUFPP city data_2024.xlsx")) %>%
        as.data.frame()
      mufpp_cities <- mufpp_cities[ ,2:1]
      names(mufpp_cities) <- c("country", "city")
      mufpp_cities <- mufpp_cities[order(mufpp_cities$country, mufpp_cities$city), ]
    
    # Identify changes in signatory cities 
      previous <- paste(mufpp_cities_2021$city, mufpp_cities_2021$country, sep = ", ") %>% as.data.frame()
      updated <- paste(mufpp_cities$city, mufpp_cities$country, sep = ", ") %>% as.data.frame()
      names(previous) <- "city"
      names(updated) <- "city"
    
    # Identify changes to list cities to add and delete from analysis
      cities_to_delete <- previous %>% anti_join(updated) %>% as.data.frame() # Cities to delete
      cities_to_add <- updated %>% anti_join(previous) %>% as.data.frame() # Cities to add
      # Check there are no differences:
      nrow(cities_to_add) - nrow(cities_to_delete) == nrow(cities_to_add) - nrow(cities_to_delete) 
      # Clean up
      rm(previous, updated, mufpp_cities_2021)

  # Data management - Fix country names to match across city list and GADM boundary data
    # Modify country names to match geodata::gadm() as needed
      gadm_ntry_names <- geodata::country_codes()$NAME %>% as.data.frame()
      mufpp_cntry_names <- unique(mufpp_cities$country) %>% as.data.frame()
      names(gadm_ntry_names) <- "country"
      names(mufpp_cntry_names) <- "country"
    
    # Code to identify the mismatched spellings:
    # mufpp_cntry_names %>% anti_join(gadm_ntry_names)
    # gadm_ntry_names %>% anti_join(mufpp_cntry_names)
    # Clean up
      rm(gadm_ntry_names, mufpp_cntry_names)
    
    # Make changes for mismatched spellings:
      mufpp_cities$country <- gsub("Ivory Coast", "Côte d'Ivoire", mufpp_cities$country)
      mufpp_cities$country <- gsub("Republic of Congo", "Congo", mufpp_cities$country)
      mufpp_cities$country <- gsub("Türkiye", "Turkey", mufpp_cities$country)
      mufpp_cities$country <- gsub("Cape Verde", "Cabo Verde", mufpp_cities$country)
    
    # Unique country names list to avoid duplicate extracts per country
      mufpp_cities <- mufpp_cities[order(mufpp_cities$country), ]
      mufpp_countries <- mufpp_cities$country %>% table() %>% as.data.frame()
      names(mufpp_countries) <- c("country", "city_counts")
      mufpp_countries$city_counts %>% sum()

# Now download the boundaries for every country with an MUFPP signatory city
  # This step creates a spatial vector collection which is a stack (boundaries and ISO code) 
    country_adm0s <- do.call("svc", lapply(mufpp_countries$country, 
                                         function(x) geodata::gadm(country=x, 
                                                                   level=0, 
                                                                   version="latest", 
                                                                   path=tempdir())))

# Crop, mask & create list of SpatRasters for each country from the Landscan global data
    # This creates a spatial raster collection from the spatial vector collection
    # And the data are the population counts within the spatial boundaries
    # Load Landscan data
    lsg_world_22 <- terra::rast(file.path(data_in, "landscan-global-2022.tif"))
  
    # Now extract the country raster
      i <- 1
      country_SpatRasters <- vector()
      while(i <= length(country_adm0s)){
        cntry_crp <- terra::crop(lsg_world_22, country_adm0s[[i]])
        cntry_msk <- terra::mask(cntry_crp, country_adm0s[[i]])
        country_SpatRasters <- c(country_SpatRasters, cntry_msk)
        i <- i + 1
      }

    # Use SpatRasters to calculate urban and total populations for each country
      # Turn off S2 for this step as it causes the loop to break for certain countries
        sf::sf_use_s2(FALSE)
        
      # Now run the loop over all countries
        i <- 1
        countries_urban_pop <- vector()
        countries_total_pop <- vector()
        while(i <= length(country_adm0s)) {
          density_polys <- terra::as.polygons(country_SpatRasters[[i]] > 200) %>% 
            sf::st_as_sf() #200 represents urban density threshold
          density_polys <- density_polys$geometry %>% sf::st_cast("POLYGON") %>% sf::st_as_sf()
          # Check if valid
          sf::st_is_valid(density_polys)
          density_polys <- density_polys %>% mutate(area = as.numeric(sf::st_area(density_polys)))
          density_polys <- density_polys %>% filter(area < max(density_polys$area) - 1)
          density_polys$pops <- exactextractr::exact_extract(country_SpatRasters[[i]], density_polys, fun = 'sum')
          cntry_urbpop <- sum(density_polys$pops)
          countries_urban_pop <- c(countries_urban_pop, cntry_urbpop)
          cntry_totpop <- global(country_SpatRasters[[i]], sum, na.rm = TRUE)[1, ]
          countries_total_pop <- c(countries_total_pop,cntry_totpop)
          i <- i + 1
        }
        # Clean up
          rm(country_adm0s, cntry_crp, cntry_msk, country_SpatRasters, 
             density_polys, cntry_totpop, cntry_urbpop, i)
      
        # Turn S2 back on
          sf::sf_use_s2(TRUE)
      
    # Assemble MUFPP values into data frame
      country_populations <- data.frame(country = mufpp_countries$country,
                                        pop_u = countries_urban_pop,
                                        totalpop_landscan = countries_total_pop)
    # Clean up
      rm(countries_total_pop, countries_urban_pop)

# Now load the GADM data, which is used to extract the city boundaries
  # Note that this is the only raw data file not included in the Github repository
      # because it is too large. It must be downloaded from the GADM website
      # https://gadm.org/download_world.html
      # Select the geopackage of six separate layers
      
  # Create vector for different admin level polygons
    adm0 <- vect(file.path(data_in, "gadm_410-levels.gpkg"), layer = "ADM_0")
    adm1 <- vect(file.path(data_in, "gadm_410-levels.gpkg"), layer = "ADM_1")
    adm2 <- vect(file.path(data_in, "gadm_410-levels.gpkg"), layer = "ADM_2")
    adm3 <- vect(file.path(data_in, "gadm_410-levels.gpkg"), layer = "ADM_3")
    adm4 <- vect(file.path(data_in, "gadm_410-levels.gpkg"), layer = "ADM_4")
    adm5 <- vect(file.path(data_in, "gadm_410-levels.gpkg"), layer = "ADM_5")

  # First for all new cities, we have to identify the ADM level and the correct name spelling 
  # City extracts are hard coded below because:
    # The administrative level where the city boundaries are located in the GADM data differs depending on the country and city
    # Some cities have names found in many countries so country must be specified. 
    # Some cities require aggregating multiple units from the GADM data
    # Some cities are not in GADM and have to use Open Street Map (OSM) instead
  
  # This commented out code provides examples for investigation to make sure the cities are pulling correct polygons
    # These print in the console
    # Look for name spelling and special characters and look for duplicate names at multiple levels
        # adm1[which(adm1$COUNTRY == "Uruguay"), ]$NAME_1 %>% sort()
        # adm1[which(adm1$COUNTRY == "Turkey"), ] |> as.data.frame() |> View()
        # adm1[which(adm1$NAME_1 == "Praia"), ]
        # adm2[which(adm2$COUNTRY == "Uruguay"), ]$NAME_2 %>% sort()
        # adm2[which(adm2$COUNTRY == "Turkey"), ] |> as.data.frame() |> View()
        # adm2[which(adm2$NAME_2 == "Lucca"), ]
        # adm2[which(adm2$NAME_2 == "Halifax" & adm2$COUNTRY == "Canada"), ]
        # adm3[which(adm3$COUNTRY == "Venezuela"), ]$NAME_3 %>% sort()
        # adm3[which(adm3$NAME_3 == "Lucca"), ]
        # adm4[which(adm4$COUNTRY == "Uganda"), ]$NAME_4 %>% sort()
        # adm4[which(adm4$NAME_4 == "Balikpapan"), ]
        # adm5[which(adm5$COUNTRY == "Indonesia"), ]$NAME_5 %>% sort()
        # adm0[grep("*Santa Fe", adm0$COUNTRY), ]$COUNTRY
        # adm1[grep("*Habana", adm1$NAME_1), ]$NAME_1
        # adm2[grep("*Habana", adm2$NAME_2), ]$NAME_2
        # adm3[grep("*Rourkela", adm3$NAME_3), ]$NAME_3
        # adm4[grep("*London", adm4$NAME_4), ]$NAME_4
        # adm5[grep("*Bamako", adm5$NAME_5), ]$NAME_5
  
# Now extract the MUFPP Cities' spatial boundaries
  # Each annual update, you have to remove here any cities in the cities_to_delete dataframe
  # Note the spellings are different from the mufpp_cities and must match GADM data to be selected correctly
  # These city extracts are memory intensive. Garbage collection ('gc()') helps reduce memory load
    # It will run as coded here with 128GB RAM 
      # If you have less, garbage collection will be needed more frequently
      # Some lines may not run under a certain RAM threshold
      mufpp_cities_vect <- adm3[which(adm3$NAME_3 == "Tiranë"), ] 
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Alger"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Luanda"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Buenos Aires"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Córdoba" & adm1$COUNTRY == "Argentina"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Esteban Echeverría"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Godoy Cruz"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Rió Grande"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Rosario" & adm2$COUNTRY == "Argentina"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "San Antonio de Areco"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_1 == "Santa Fe" & adm2$NAME_2 == "La Capital"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Tandil"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Melbourne"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Sydney"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Wien"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Brugge"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Bruxelles"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Gent"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Leuven"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Liège"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Namur"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Oostende"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "La Paz" & adm1$COUNTRY == "Bolivia"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Sucre" & adm3$COUNTRY == "Bolivia"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Araraquara"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Belo Horizonte"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Campinas"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Curitiba"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Maricá"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Osasco"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Porto Alegre"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Recife"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Rio de Janeiro"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Salvador" & adm2$COUNTRY == "Brazil"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "São Paulo"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Bobo-Dioulasso"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Ouagadougou"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Bafoussam 1"), ] %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Bafoussam 2"), ]) %>%
                               terra::union(adm3[which(adm3$NAME_3 == "Bafoussam 3"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Bamenda 1"), ] %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Bamenda 2"), ]) %>%
                               terra::union(adm3[which(adm3$NAME_3 == "Bamenda 3"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Douala 1"), ] %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Douala 2"), ]) %>%
                               terra::union(adm3[which(adm3$NAME_3 == "Douala 3"), ]) %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Douala 4"), ]) %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Douala 5"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Ebolowa 1"), ] %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Ebolowa 2"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Guelph"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Halifax" & adm2$COUNTRY == "Canada"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Communauté-Urbaine-de-Montréal"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Toronto"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Vancouver"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Praia"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "N'Djamena"), ][1] %>%
                               terra::union(adm2[which(adm2$NAME_2 == "N'Djamena"), ][2]) %>% aggregate())
      
      gc()
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Santiago Metropolitan" & adm1$COUNTRY == "Chile"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Beijing"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Chongqing"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Guangzhou"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Shanghai"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Bogotá D.C."), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Manizales"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Medellin"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Santiago de Cali"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Santa Ana" & adm2$COUNTRY == "Costa Rica"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Zagreb"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Ciudad de la Habana"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "København"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Kolding"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Chone"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Portoviejo"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Quito"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "San Salvador" & adm1$COUNTRY == "El Salvador"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Addis Abeba"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Bordeaux"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Dijon"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Grenoble"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Le Havre"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Lyon"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Marseille"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Montpellier" & adm3$COUNTRY == "France"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Montreuil"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm5[which(adm5$NAME_5 == "Mouans-Sartoux"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Nantes" & adm3$COUNTRY == "France"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Paris"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Rennes"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Strasbourg"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Banjul"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Berlin"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Bremerhaven"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Köln"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Frankfurt am Main"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Accra", format_out = "sf_polygon", featuretype = "city", silent = FALSE) %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Tamale"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Athens" & adm3$COUNTRY == "Greece"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Thessaloniki"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Guatemala"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Tegucigalpa", format_out = "sf_polygon", featuretype = "city", silent = FALSE) %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Budapesti"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Bhopal"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Chandigarh"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Indore"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Jabalpur"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Jammu"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Panaji"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Pune"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Rajkot"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Rourkela", format_out = "sf_polygon", featuretype = "city", silent = FALSE) %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Sagar" & adm3$NAME_1 == "Madhya Pradesh"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Surat"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Tumkur"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Ujjain"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Balikpapan"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Bandung"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Banjar Baru"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Bogor"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Bontang"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Denpasar"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Gorontalo"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Makassar"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Pekanbaru"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Semarang"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Sukabumi"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Surakarta"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Tarakan"), ])
      
      gc()
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Dublin"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Herzliya", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[1,] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Tel Aviv"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Ancona"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Andria"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Aosta"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Bari" & adm3$COUNTRY == "Italy"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Bergamo"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Bologna"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Cagliari"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Capannori"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Castel Del Giudice"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Cremona" & adm3$COUNTRY == "Italy"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Florence" & adm2$COUNTRY == "Italy"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Foggia"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Genova"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Lecco"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Livorno" & adm3$COUNTRY == "Italy"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Lucca"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Milano"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Modena"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Molfetta"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Palermo"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Parma"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Lucca"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Roma" & adm3$COUNTRY == "Italy"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Trento"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Torino"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Udine"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Venezia"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Vicenza"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Abidjan"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Kyoto"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Osaka"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Tokyo" & adm1$COUNTRY == "Japan"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Amman"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Salt"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Nur-Sultan", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[[2]][1,] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Kisumu"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Nairobi"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Biškek"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Riga"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Antananarivo"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Seberang Perai Selatan"), ] %>% 
                               terra::union(adm2[which(adm2$NAME_2 == "Seberang Perai Tengah"), ]) %>%
                               terra::union(adm2[which(adm2$NAME_2 == "Seberang Perai Utara"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Bamako"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Nouakchott"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Guadalajara" & adm2$COUNTRY == "México"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Mérida"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Distrito Federal" & adm1$COUNTRY == "México"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Pachuca de Soto"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Chişinău"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Ulaanbaatar"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Chimoio", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[1,] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Maputo 1"), ] %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Maputo 2"), ]) %>%
                               terra::union(adm3[which(adm3$NAME_3 == "Maputo 3"), ]) %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Maputo 4"), ]) %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Maputo 5"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Pemba Cidade" & adm3$COUNTRY == "Mozambique"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Cidade De Quelimane" & adm3$COUNTRY == "Mozambique"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Windhoek", format_out = "sf_polygon", featuretype = "city", silent = FALSE) %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Almere"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Amsterdam"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Ede"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Groningen" & adm2$COUNTRY == "Netherlands"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Rotterdam"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "The Hague", format_out = "sf_polygon", featuretype = "city", silent = FALSE) %>% vect() %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Utrecht"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Wellington" & adm2$COUNTRY == "New Zealand"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Agadez", format_out = "sf_polygon", featuretype = "city", silent = FALSE) %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Gaya" & adm3$COUNTRY == "Niger"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Niamey", format_out = "sf_polygon", featuretype = "city", silent = FALSE) %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Bethlehem"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Jericho"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Lima" & adm2$COUNTRY == "Peru"), ] %>% 
                               terra::union(adm2[which(adm2$NAME_2 == "Callao" & adm2$COUNTRY == "Peru"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Quezon City"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Warszawa"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Wrocław"), ])
      gc()
      
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Funchal (Santa Luzia)"), ] %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Funchal (São Pedro)"), ]) %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Funchal (Sé)"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Lisboa"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Torres Vedras (Santa Maria Do Ca"), ] %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Torres Vedras (São Pedro E São T"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Brazzaville"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Brasov"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Bucharest"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Cheboksary"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Kazan", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[[2]]  %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Moscow City"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Nizhny Novgorod", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[[2]] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Samara", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[2,] |> vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Dakar"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Freetown1"), ] %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Freetown2"), ]) %>%
                               terra::union(adm3[which(adm3$NAME_3 == "Freetown3"), ]) %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Freetown4"), ]) %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Freetown5"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Ljubljana"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Mogadisho"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "City of Cape Town"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Ethekwini"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "City of Johannesburg"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Daegu"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Hwaseong"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Jangseong"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Naju"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Seoul"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Wanju"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Yeosu"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Barcelona"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Bilbao"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Cádiz"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Córdoba"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Dénia"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Donostia-San Sebastián"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Fuenlabrada"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Granollers"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Madrid"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Málaga"), ][2])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Rivas-Vaciamadrid"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Valencia"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Valladolid"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Vitoria-Gasteiz"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm4[which(adm4$NAME_4 == "Zaragoza"), ][1])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Colombo" & adm2$COUNTRY == "Sri Lanka"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Basel" & adm3$COUNTRY == "Switzerland"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Genève"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Lausanne"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Zürich"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Arusha"), ] %>% 
                               terra::union(adm2[which(adm2$NAME_2 == "Arusha Urban"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Bangkok Metropolis"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Chiang Mai"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Carthage"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Tunis"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Efeler", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[2, ] %>% vect() %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Mezitli", format_out = "sf_polygon", featuretype = "city", silent = FALSE) %>% vect() %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Nilüfer"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Istanbul"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Mbale"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Abu Dhabi"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Dubai"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Birmingham"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Brighton and Hove"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Bristol" & adm3$COUNTRY == "United Kingdom"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Glasgow"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm3[which(adm3$NAME_3 == "Bolton" & adm3$COUNTRY == "United Kingdom"), ] %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Bury" & adm3$COUNTRY == "United Kingdom"), ]) %>%
                               terra::union(adm3[which(adm3$NAME_3 == "Manchester" & adm3$COUNTRY == "United Kingdom"), ]) %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Oldham" & adm3$COUNTRY == "United Kingdom"), ]) %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Rochdale" & adm3$COUNTRY == "United Kingdom"), ]) %>% 
                               terra::union(adm3[which(adm3$NAME_3 == "Salford" & adm3$COUNTRY == "United Kingdom"), ]) %>%
                               terra::union(adm3[which(adm3$NAME_3 == "Stockport" & adm3$COUNTRY == "United Kingdom"), ]) %>%
                               terra::union(adm3[which(adm3$NAME_3 == "Tameside" & adm3$COUNTRY == "United Kingdom"), ]) %>%
                               terra::union(adm3[which(adm3$NAME_3 == "Trafford" & adm3$COUNTRY == "United Kingdom"), ]) %>%
                               terra::union(adm3[which(adm3$NAME_3 == "Wigan" & adm3$COUNTRY == "United Kingdom"), ]) %>% aggregate())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Greater London", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[1,] %>% vect())
      gc()
      
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Austin", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[[2]][1,] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Baltimore", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[1,] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Boston", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[1,] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Chicago", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[1,] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Hamilton" & adm2$NAME_1 == "Ohio"), ]) #Cincinatti
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Columbus, Ohio", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[1,] %>% vect())
        x <- getbb(place_name = "Los Angeles", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[[1]] %>% 
          st_cast("POLYGON") %>% 
          st_cast("LINESTRING") %>% 
          st_cast("POLYGON")
      mufpp_cities_vect <- c(mufpp_cities_vect, x[1, ] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Miami", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[[1]][1,] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Minneapolis", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[[1]] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "New Haven", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[1,] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "New Port Richey", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[[2]] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "New York", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[[2]][1,] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Pittsburgh", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[1,] %>% vect())
        x <- getbb(place_name = "San Francisco", format_out = "sf_polygon", featuretype = "city", silent = FALSE)[[2]] %>% 
          st_cast("POLYGON") %>% 
          st_cast("LINESTRING") %>% 
          st_cast("POLYGON")
      mufpp_cities_vect <- c(mufpp_cities_vect, x[2, ] %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, getbb(place_name = "Washington DC", format_out = "sf_polygon", featuretype = "city", silent = FALSE) %>% vect())
      mufpp_cities_vect <- c(mufpp_cities_vect, adm1[which(adm1$NAME_1 == "Montevideo"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Ezequiel Zomora"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Kitwe"), ])
      mufpp_cities_vect <- c(mufpp_cities_vect, adm2[which(adm2$NAME_2 == "Lusaka"), ])

  # Extract population totals per city  
    lsg_world_22 <- terra::rast(file.path(data_in, "landscan-global-2022.tif"))
    i <- 1
    all_pops <- vector()
    while(i <= length(mufpp_cities_vect)){
      pops <- terra::extract(lsg_world_22, mufpp_cities_vect[[i]], fun = 'sum', na.rm = TRUE)[1,2]
      all_pops <- c(all_pops, pops)
      i <- i + 1
    }
    
  # Assemble values into data frame
    # For this to be accurate, the cities list has to be in the same order as the vectors that are put into all_pops
      city_populations <- data.frame(cities = mufpp_cities,
                                     city_pop = all_pops)
    
    # Add in the total and urban populations
      mufpp_2023 <- left_join(city_populations, country_populations, by = c("cities.country" = "country"))
      mufpp_2023 <- mufpp_2023 %>%
        select(c(1,3,4)) %>%
        group_by(cities.country, pop_u) %>%
        summarize(mufpp_pop = sum(city_pop)) %>%
        ungroup() %>%
        dplyr::mutate(mufppurbshare = round((mufpp_pop / pop_u)*100, 2),
                      pop_u = pop_u/1000) %>%
        rename(country = cities.country) %>%
        select(c(1,2,4)) %>%
        unique() %>%
        pivot_longer(2:3, names_to = "indicator", values_to = "value") %>%
        mutate(unit = case_when(indicator == "mufppurbshare" ~ "% urban population",
                                indicator == "pop_u" ~ "thousands"),
               indicator = case_when(indicator == "mufppurbshare" ~ "% urban population living in cities signed onto the Milan Urban Food Policy Pact",
                                     indicator == "pop_u" ~ "Urban population"),
               year = 2023) # Assign to 2023, populations from 2022 but city update from Jan 2024
      
      # Add M49 codes and fix country names
        mufpp_2023$country2 <- countrycode::countrycode(mufpp_2023$country, origin = 'country.name', destination = 'un.name.en', warn = TRUE, nomatch = NA)  
        mufpp_2023 <- mufpp_2023 %>% mutate(country2 = case_when(is.na(country2) ~ country,
                                                                   TRUE ~ country2)) %>%
          select(-c("country")) %>% 
          rename(country = country2) 
        mufpp_2023$ISO3 <- countrycode::countrycode(mufpp_2023$country, origin = 'country.name', destination = 'iso3c', warn = TRUE, nomatch = NA) 
        mufpp_2023$M49_code <- countrycode::countrycode(mufpp_2023$ISO3, origin = 'iso3c', destination = 'un', warn = TRUE, nomatch = NA) 
        
      # Organize
        mufpp_2023 <- mufpp_2023[, col_order]
        saveRDS(mufpp_2023, file = file.path(data_out, "mufpp_2023.rds"))
        
    # Clean up
      rm(adm0, adm1, adm2, adm3, adm4, adm5, city_populations, cities_to_add, cities_to_delete, country_populations, lsg_world_22, mufpp_cities, mufpp_cities_vect, mufpp_countries, x)
```

$~$

#### Compile final dataset

```{r, warning = FALSE, messages = FALSE}
# List all the data frames
  # If needed, load the individual data frames
    dfs <- list.files(path = file.path(data_out),
                      pattern = "*.rds$",
                      full.names = TRUE)
    file_names <-  gsub(pattern = "\\.rds$", replacement = "", x = basename(dfs))
    data_list <- lapply(dfs, readRDS) 
    names(data_list) <- file_names 
    data_list
    list2env(data_list, .GlobalEnv)
    rm(FSCI_2024, data_list)

    # Bind all rows
      dfs = sapply(.GlobalEnv, is.data.frame) 
      FSCI_2024 <- do.call(rbind, mget(names(dfs)[dfs]))

# Rectangularize the data (make sure there is a country-year row for every indicator with NA if there is no data)
  # Save country info and units to add to new records created in rectangularization
    countryinfo <- FSCI_2024 %>% select(c(country, ISO3, M49_code)) %>% unique()
    units <- FSCI_2024 %>% select(c(indicator, unit)) %>% unique()
  # Rectangularize
    FSCI_2024 <- FSCI_2024 %>% tidyr::complete(country, indicator, year) 
      # Add "None" for categorical variables
        FSCI_2024 <- FSCI_2024 %>%
          mutate(value = case_when(indicator == "Presence of national health-related food environment policies" & year == 2023 & is.na(value) ~ "none",
                                   TRUE ~ value),
                 value = case_when(indicator == "Presence of a national food system transformation pathway" & year %in% c(2022,2024) & is.na(value) ~ "0", 
                                   TRUE ~ value),
                 value = case_when(indicator == "Guarantees for public access to information (SDG 16.10.2)" & is.na(value) & year == 2022 ~ "0",
                                   TRUE ~ value),
                 value = case_when(indicator == "% urban population living in cities signed onto the Milan Urban Food Policy Pact" & is.na(value) & year == 2023 ~ "0",
                                   TRUE ~ value))
  # Clean up
    FSCI_2024 <- FSCI_2024 %>% filter(!(is.na(country))) %>%
      filter(!(is.na(year))) %>%
      select(-c(ISO3, M49_code, unit))
    FSCI_2024 <- left_join(FSCI_2024, countryinfo, by = "country")
    FSCI_2024 <- left_join(FSCI_2024, units, by = "indicator")
  
# Organize
  FSCI_2024 <- FSCI_2024[, col_order]

# Join additional codebook data and organizing variables
  codebook <- read_excel(here::here("Monitoring", "Supplementary Data 1 - Metadata and Codebook.xlsx"), 
                         sheet = "Codebook")
  country_classification <- read_excel(here::here("Monitoring", "Supplementary Data 1 - Metadata and Codebook.xlsx"), 
                         sheet = "Country classification") %>%
    # Remove M49 code because it is already in the data frame
    select(-c(12))
  
  # Merge in codebook information
    FSCI_2024 <- left_join(FSCI_2024, codebook, by = c("indicator" = "variable_label")) %>%
      # Remove country to bring in UN member state names
      select(-c(country)) %>%
      filter(!(ISO3 == "" | is.na(M49_code)))
    FSCI_2024 <- left_join(FSCI_2024, country_classification, by = c("ISO3", "M49_code"))
  
  # Fix characters in Turkey, Cote D'Ivoire, and Curacao
    FSCI_2024 <- FSCI_2024 %>%
      mutate(country = case_when(country == "Turkiye" ~ "Türkiye",
                                 country == "Cote D'Ivoire" ~ "Côte d'Ivoire",
                                 country == "Curacao" ~ "Curaçao",
                                 TRUE ~ country))

# Remove any non-UN member states and observations prior to 2000
  FSCI_2024 <- FSCI_2024 %>%
    filter(member_state == "YES") %>%
    filter(year>=2000) %>%
    select(-c(20:25))
  
# Arrange data
  FSCI_2024 <- FSCI_2024 %>%
    relocate(country, .before = "M49_code") 
  
  FSCI_2024 <- FSCI_2024[with(FSCI_2024, order(country, year, variable_order)),]
    
# Other data management
  FSCI_2024 <- FSCI_2024 %>%
    unique() %>%
    mutate(across(5, as.numeric)) %>%
    mutate(across(c(1,3:4, 8:9, 12:19), as.factor)) %>%
      # Make sure there is no duplicate value for India in 2015 for ESA Agricultural land (from functional integrity dataset)
    filter(!(country == "India" & indicator == "Agricultural land area - ESA" & value == 0))

# Clean up
  rm(codebook, country_classification, countryinfo, units)

# Now add in the weighted means (global, by income group, and by region)
  # Filter out the non-numerical indicators
    data <- FSCI_2024 %>%
      filter(!(unit == "categorical")) %>%
      mutate(value = as.numeric(value))

  # Mutate the weighting variables wide
    weightvars <- data %>%
      filter(is.na(indicator_order)) %>%
      select(-c(unit, short_label, indicator, 10:16,19:20)) %>%
      pivot_wider(id_cols = c("country", "year", "M49_code", "ISO3", "income_group", "FSCI_region"),
                  names_from = variable,
                  values_from = value)

  # Filter weighting variables from the long data and merge back in wide form
    data <- data %>%
      filter(!(is.na(indicator_order))) %>%
      left_join(., weightvars, by = c("country", "year", "ISO3", "M49_code", "income_group", "FSCI_region"))
  
  # Calculate weighted mean
    # Define weights
    data <- data %>%
      mutate(mean_weighting = as.character(mean_weighting)) %>%
      mutate(weight = case_when(mean_weighting == "totalpop" ~ totalpop,
                                mean_weighting == "production_beef" ~ production_beef,
                                mean_weighting == "production_cerealsexclrice" ~ production_cerealsexclrice,
                                mean_weighting == "production_cowmilk" ~ production_cowmilk,
                                mean_weighting == "production_rice" ~ production_rice,
                                mean_weighting == "agland" ~ agland,
                                mean_weighting == "agland_ESA" ~ agland_ESA,
                                mean_weighting == "agland_minspecies" ~ agland_minspecies,
                                mean_weighting == "GDP" ~ GDP,
                                mean_weighting == "landarea" ~ landarea,
                                mean_weighting == "pop_u" ~ pop_u, 
                                mean_weighting == "cropland" ~ cropland,
                                mean_weighting == "animals_beef" ~ animals_beef, 
                                mean_weighting == "animals_cowmilk" ~ animals_cowmilk, 
                                mean_weighting == "areaharvested_cereals" ~ areaharvested_cereals, 
                                mean_weighting == "areaharvested_fruit" ~ areaharvested_fruit, 
                                mean_weighting == "areaharvested_veg" ~ areaharvested_veg, 
                                mean_weighting == "unweighted" ~ 1,
                                TRUE ~ NA),
             # Replace 0 as NA (weight = 0 happens when there is no area harvested, for example)
             weight = case_when(weight == 0 ~ NA,
                                TRUE ~ weight))
    # Compute
      globalmeans <- data %>%
        arrange(indicator, year) %>%
        # Global mean
          group_by(indicator, year) %>%
          filter(!(is.na(value))) %>%
          filter(!(is.na(weight))) %>%
          mutate(globalmean = stats::weighted.mean(value, weight, na.rm = TRUE)) %>%
          ungroup() %>%
        select(c(5,8,40)) %>%
        unique()
    
      # Regional mean
        regionmeans <- data %>%
          group_by(indicator, year, FSCI_region) %>%
          filter(!(is.na(FSCI_region))) %>%
          filter(!(is.na(value))) %>%
          filter(!(is.na(weight))) %>%
          mutate(regionmean = stats::weighted.mean(value, weight, na.rm = TRUE)) %>%
          ungroup() %>%
          select(c(5,8,18,40)) %>%
          unique()
  
      # Income group mean
        incomemeans <- data %>%
          group_by(indicator, year, income_group) %>%
          filter(!(is.na(income_group))) %>%
          filter(!(is.na(value))) %>%
          filter(!(is.na(weight))) %>%
          mutate(incomegrpmean = stats::weighted.mean(value, weight, na.rm = TRUE)) %>%
          ungroup() %>%
          select(c(5,8,17,40)) %>%
          unique()
    
  # Merge the means back into the FSCI_2024 dataframe
    FSCI_2024 <- FSCI_2024 %>%
      # Remove the weighting variables in the long data
      filter(!(is.na(indicator_order)))
      # Remove excess variables from the dataframe with the weighting variables wide
      data <- data %>%
        select(c(1,5,8,21:39)) 
      # Now join in with the weight variables as columns
      FSCI_2024 <- left_join(FSCI_2024, data, by = c("country", "year", "variable"))
      # Now add the grouped weighted means 
      FSCI_2024 <- left_join(FSCI_2024, globalmeans, by = c("year", "variable"))
      FSCI_2024 <- left_join(FSCI_2024, regionmeans, by = c("year", "variable", "FSCI_region"))
      FSCI_2024 <- left_join(FSCI_2024, incomemeans, by = c("year", "variable", "income_group")) 
      
  # Remove extreme values for change in cropland >-200% (Montenegro 2013-2017)
      FSCI_2024 <- FSCI_2024 %>%
        mutate(value = case_when(indicator == "Cropland area change" & country == "Montenegro" & year %in% 2013:2017 ~ "",
                                 TRUE ~ value))
      
  # Clean up
    rm(data, weightvars, globalmeans, incomemeans, regionmeans)

  # remove functions
    rm(getdata2, getdata3, getdata_fao, getdata_sdg)
      
# Save dataset
  saveRDS(FSCI_2024, file = file.path(data_out, "FSCI_2024.rds"))
  readr::write_csv(FSCI_2024, file = file.path(data_out, "FSCI_2024.csv.gz"))
      
```

$~$

# *Import and shape the global expert elicitation results*

```{r, warning = FALSE, messages = FALSE, echo = TRUE}
# Import the matrix completed by expert elicitation
  rawdata_all <- readxl::read_xlsx(file.path(data_in,"Interaction_scoring_sheet_All Groups_2024_March.xlsx"), sheet = "Sheet 1 - interaction_scoring_s")
  labels <- readxl::read_xlsx(file.path(data_in,"Interaction_scoring_sheet_All Groups_2024_March.xlsx"), sheet = "Indicator names and labels")

# Start with the first direction of relationship (Column E)
  rawdata <- rawdata_all %>%
    select(c(1:2,4:5)) %>%
    # Label the columns
    rename(theme = 1,
           indicator = 2,
           dependent = 3,
           relationship = 4) %>%
    # Now remove the rows of header information and empty end rows
    filter(row_number() %notin% 1,
           row_number() %notin% 2452:2458) %>%
    # Factor the indicator names and themes, make the relationship numeric
    mutate(theme = as.factor(theme),
           indicator = as.factor(indicator),
           dependent = as.factor(dependent),
           relationship = as.numeric(relationship)) %>%
    # Replace NA with 0 (no relationship)
    mutate(relationship = case_when(is.na(relationship) ~ 0,
                                    TRUE ~ relationship))

# Merge in the short labels for the indicators for figures
  rawdata <- left_join(rawdata, labels, by = "indicator") %>%
    rename(from = short_label,
           from_theme = theme.y) %>%
    select(-c(indicator_order))
  rawdata <- left_join(rawdata, labels, by = c("dependent" = "indicator")) %>%
    rename(to = short_label,
           to_theme = theme) %>%
    select(-c(theme.x, indicator, dependent, indicator_order)) %>%
    relocate(relationship, .after = to_theme) %>%
    mutate(to = as.factor(to),
           from = as.factor(from),
           from_theme = as.factor(from_theme),
           to_theme = as.factor(to_theme))

# Remove the theme columns
  raw_wide <- rawdata %>%
    select(-c(contains("theme"))) %>%
    # Pivot wide
    pivot_wider(names_from = to, 
                values_from = relationship, 
                values_fill = 0) %>%
    relocate("Cost of healthy diet", .after = from)
  
# Confirm indicators are in the correct order
  raw_wide <- left_join(raw_wide, labels, by = c("from" = "short_label")) %>%
    select(-c(indicator, theme))
  raw_wide <- raw_wide[order(raw_wide$indicator_order), ]
  raw_wide <- raw_wide %>%
    select(-c(indicator_order)) %>%
    relocate(`Social capital index`, .before = `Mobile phones per 100 people`)


# Convert to a matrix
# Remove the first column because matrices can only have one class of data
  matrix1 <- as.matrix(raw_wide[, -1]) # eliminate rownames column to get numerical matrix

# Add back the row names
  rownames(matrix1) <- raw_wide$from # assign rownames

# Square and cube the matrix
  matrix2 <- matrix1 %*% matrix1
  matrix3 <- matrix1 %*% matrix1 %*% matrix1

# Reshape the second and third order connections into long data frames
# Create a function to reshape matrix to data frame
  reshapetodf <- function(input_matrix) {
    input <- data.frame(input_matrix) 
    input$from <- row.names(input)   
    input <- input %>%
      pivot_longer(1:50, names_to = "to", values_to = "relationship") %>%
      mutate(to = stringr::str_replace_all(to, "\\.", " "),        
             to = stringr::str_replace_all(to, "   ", " "),
             to = case_when(to == "NCD Protect" ~ "NCD-Protect",
                            to == "NCD Risk" ~ "NCD-Risk",
                            TRUE ~ to)) 
    return(input)
  }

# Execute the function on the matrices
  df_order2 <- reshapetodf(matrix2)
  df_order3 <- reshapetodf(matrix3)

# Add from theme to the long second and third order connections
  rawdata_from <- rawdata %>% select(c("from", "from_theme")) %>% unique()
  df_order2 <- left_join(df_order2, rawdata_from, by = "from") 
  df_order3 <- left_join(df_order3, rawdata_from, by = "from") 

# Add indicator order for from variable
  rawdata <- left_join(rawdata, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    rawdata <- rawdata %>% rename(from_order = indicator_order)
  df_order2 <- left_join(df_order2, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    df_order2 <- df_order2 %>% rename(from_order = indicator_order)
  df_order3 <- left_join(df_order3, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    df_order3 <- df_order3 %>% rename(from_order = indicator_order)

```

$~$

Repeat for the relationships identified in the other direction (Column F)
```{r, warning = FALSE, messages = FALSE, echo = TRUE}
# Load data and clean
  rawdata2 <- rawdata_all %>%
    select(c(1:2,4,6)) %>%
    # Label the columns
    rename(theme = 1,
           dependent = 2,
           indicator = 3,
           relationship = 4) %>%
    # Fix the open budget index name in the dependent column
    mutate(dependent = case_when(dependent == "Open Budget Index" ~ "Open Budget Index Score",
                                 TRUE ~ dependent)) %>%
    # Now remove the rows of header information and empty end rows
    filter(row_number() %notin% 1,
           row_number() %notin% 2452:2458) %>%
    # Factor the indicator names and themes, make the relationship numeric
    mutate(theme = as.factor(theme),
           indicator = as.factor(indicator),
           dependent = as.factor(dependent),
           relationship = as.numeric(relationship)) %>%
    # Replace NA with 0 (no relationship)
    mutate(relationship = case_when(is.na(relationship) ~ 0,
                                    TRUE ~ relationship))

# Merge in the short labels for the indicators for figures
  rawdata2 <- left_join(rawdata2, labels, by = "indicator") %>%
    rename(from = short_label,
           from_theme = theme.y) %>%
    select(-c(indicator_order))
  rawdata2 <- left_join(rawdata2, labels, by = c("dependent" = "indicator")) %>%
    rename(to = short_label,
           to_theme = theme) %>%
    select(-c(1:3)) %>%
    relocate(relationship, .after = to_theme) %>%
    select(-c(indicator_order))
  
  # Remove the theme columns
  raw_wide2 <- rawdata2 %>%
    select(-c(contains("theme"))) %>%
    # Pivot wide
    pivot_wider(names_from = to, 
                values_from = relationship, 
                values_fill = 0) %>%
    relocate("Cost of healthy diet", .after = from) %>%
    filter(!(is.na(from)))
  
# Confirm indicators are in the correct order
  raw_wide2 <- left_join(raw_wide2, labels, by = c("from" = "short_label")) %>%
    select(-c(indicator, theme))
  raw_wide2 <- raw_wide2[order(raw_wide2$indicator_order), ]
  raw_wide2 <- raw_wide2 %>%
    select(-c(indicator_order)) %>%
    relocate(`Social capital index`, .before = `Mobile phones per 100 people`)

# Convert to matrix
  matrix1_v2 <- as.matrix(raw_wide2[, -1]) # eliminate rownames column to get numerical matrix

# Add back the row names
  rownames(matrix1_v2) <- raw_wide2$from # assign rownames

# Square and cube the matrix
  matrix2_v2 <- matrix1_v2 %*% matrix1_v2
  matrix3_v2 <- matrix1_v2 %*% matrix1_v2 %*% matrix1_v2

# Reshape the second and third order connections into long data frames
# Add from theme to the long second and third order connections
  rawdata_from2 <- rawdata2 %>% select(c("from", "from_theme")) %>% unique %>%
    filter(!(is.na(from))) %>%
    collapse::roworderv(neworder = 50)

  df_order2_v2 <- reshapetodf(matrix2_v2) 
  df_order3_v2 <- reshapetodf(matrix3_v2) 

# Add from theme to the long second and third order connections
  rawdata_from_v2 <- rawdata2 %>% select(c("from", "from_theme")) %>% unique() %>%
    filter(!(is.na(from)))
  df_order2_v2 <- left_join(df_order2_v2, rawdata_from, by = "from") 
  df_order3_v2 <- left_join(df_order3_v2, rawdata_from, by = "from") 
  
# Add indicator order variable for the from variable
  rawdata2 <- left_join(rawdata2, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    rawdata2 <- rawdata2 %>% rename(from_order = indicator_order)
  df_order2_v2 <- left_join(df_order2_v2, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    df_order2_v2 <- df_order2_v2 %>% rename(from_order = indicator_order)
  df_order3_v2 <- left_join(df_order3_v2, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    df_order3_v2 <- df_order3_v2 %>% rename(from_order = indicator_order)

```

Create a new data frame that merges column E and F information, ensuring all relationships identified are included, and preserving the directionality of the relationships.  
```{r, warning = FALSE, messages = FALSE, echo = TRUE}

# Create combined matrix by adding matrix 1 (column E) to matrix1_v2 (column F)

# Add the matrix elements together into a new matrix
  combo_matrix_keepbidirect <- matrix1 + matrix1_v2

# Now any cells with causality in both directions have a value of 2 - replace with 1
  combo_matrix <- combo_matrix_keepbidirect
  combo_matrix[combo_matrix==2] <- 1

# Reshape to data frame, fixing indicator names that lose punctuation in the matrix conversion
  combo_df <- reshapetodf(combo_matrix) %>%
    mutate(to = str_replace_all(to, "Conservation of genetic resources  plants", "Conservation of genetic resources, plants")) %>%
    mutate(to = str_replace_all(to, "Conservation of genetic resources  animals", "Conservation of genetic resources, animals")) %>%
    mutate(to = str_replace_all(to, "Minimum dietary diversity  women", "Minimum dietary diversity, women")) %>%
    mutate(to = str_replace_all(to, "Minimum dietary diversity  child", "Minimum dietary diversity, child")) %>%
    mutate(to = str_replace_all(to, "Ultra processed food sales", "Ultra-processed food sales"))
  
  combo_df_keepbidirect <- reshapetodf(combo_matrix_keepbidirect)  %>%
    mutate(to = str_replace_all(to, "Conservation of genetic resources  plants", "Conservation of genetic resources, plants")) %>%
    mutate(to = str_replace_all(to, "Conservation of genetic resources  animals", "Conservation of genetic resources, animals"))  %>%
    mutate(to = str_replace_all(to, "Minimum dietary diversity  women", "Minimum dietary diversity, women")) %>%
    mutate(to = str_replace_all(to, "Minimum dietary diversity  child", "Minimum dietary diversity, child")) %>%
    mutate(to = str_replace_all(to, "Ultra processed food sales", "Ultra-processed food sales"))

# Add from theme 
  combo_df <- left_join(combo_df, rawdata_from, by = "from") 
  combo_df_keepbidirect <- left_join(combo_df_keepbidirect, rawdata_from, by = "from") 

# Square and cube the matrix
  matrix2_combo <- combo_matrix %*% combo_matrix
  matrix3_combo <- combo_matrix %*% combo_matrix %*% combo_matrix

# Reshape matrices to data frame
  df_order2_combo <- reshapetodf(matrix2_combo) 
  df_order3_combo <- reshapetodf(matrix3_combo) 

# Add from theme to the long second and third order connections
  df_order2_combo <- left_join(df_order2_combo, rawdata_from, by = "from")
  df_order3_combo <- left_join(df_order3_combo, rawdata_from, by = "from") 
  
# Add indicator order variable for the from variable
  combo_df <- left_join(combo_df, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    combo_df <- combo_df %>% rename(from_order = indicator_order)
  combo_df_keepbidirect <- left_join(combo_df_keepbidirect, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    combo_df_keepbidirect <- combo_df_keepbidirect %>% rename(from_order = indicator_order)
  df_order2_combo <- left_join(df_order2_combo, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    df_order2_combo <- df_order2_combo %>% rename(from_order = indicator_order)
  df_order3_combo <- left_join(df_order3_combo, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    df_order3_combo <- df_order3_combo %>% rename(from_order = indicator_order)
    
# Clean up
  rm(raw_wide, raw_wide2)
  
# Bring back theme 
  combo_df_keepbidirect <- left_join(combo_df_keepbidirect, rawdata[,c("to", "to_theme")], by = "to") %>% unique()

# Save
  saveRDS(combo_df_keepbidirect, file = file.path(data_out, "Interactions_ExpertElicit_Bidirect.rds"))
```

$~$

Combine matrices keeping lowest order connection for each pair.
```{r, warning = FALSE, messages = FALSE, echo = TRUE}
  # Replace all values in matrix 2 with 2, and matrix 3 with 3 (indicating the order of connection between each pair of variables instead of the number of pathways connecting them)
    matrix2_combo[matrix2_combo > 0] <- 2
    matrix3_combo[matrix3_combo > 0] <- 3
  
    matrix_combined_combo <- ifelse(combo_matrix == 1, combo_matrix, matrix2_combo) # keep 1's from matrix 1, otherwise use the values of matrix 2
    matrix_combined_combo <- ifelse(matrix_combined_combo == 0, matrix3_combo, matrix_combined_combo) # now use the values from matrix 3 only if the combo matrix cell is 0 (no first or second order connection)
  
  # Reshape
    matrix_combined_df_combo <- reshapetodf(matrix_combined_combo) %>%
      mutate(from = as.factor(from))  %>%
      mutate(to = str_replace_all(to, "Conservation of genetic resources  plants", "Conservation of genetic resources, plants")) %>%
      mutate(to = str_replace_all(to, "Conservation of genetic resources  animals", "Conservation of genetic resources, animals"))  %>%
      mutate(to = str_replace_all(to, "Minimum dietary diversity  women", "Minimum dietary diversity, women")) %>%
      mutate(to = str_replace_all(to, "Minimum dietary diversity  child", "Minimum dietary diversity, child")) %>%
      mutate(to = str_replace_all(to, "Ultra processed food sales", "Ultra-processed food sales"))
  
  # Bring back theme 
    matrix_combined_df_combo <- left_join(matrix_combined_df_combo, rawdata[,c("from", "from_theme")], by = "from") %>% unique()
    matrix_combined_df_combo <- left_join(matrix_combined_df_combo, rawdata[,c("to", "to_theme")], by = "to") %>% unique()
    
  # Bring back variable order for from
    matrix_combined_df_combo <- left_join(matrix_combined_df_combo, labels[,c("short_label", "indicator_order")], by = c("from" = "short_label"))
    matrix_combined_df_combo <- matrix_combined_df_combo %>% rename(from_order = indicator_order)

  # Save
    saveRDS(matrix_combined_df_combo, file = file.path(data_out, "Interactions_ExpertElicit_LowestConnect.rds"))

# Save data sets in format needed for network diagrams
    saveRDS(combo_df, file = file.path(data_out, "Interactions_ExpertElicit_Direct.rds"))
    saveRDS(combo_matrix, file = file.path(data_out, "Interactions_ExpertElicit_DirectMatrix.rds"))
    
# Clean up
    rm(df_order2, df_order2_combo, df_order2_v2, df_order3, df_order3_combo, df_order3_v2, duplicate_pairs, matrix_combined_combo, matrix1, matrix1_v2, matrix2, matrix2_v2, matrix2_combo, matrix3, matrix3_combo, matrix3_v2, rawdata, rawdata_all, rawdata_from, rawdata_from2, rawdata_from_v2, combo_matrix_keepbidirect, rawdata2)

```

$~$

Now export the combined matrix pairs into the literature search analysis as they will form the basis of the first step in the search (naive search).
```{r, warning = FALSE, messages = FALSE, echo = TRUE}

# Develop a data frame of the indicator pairs
  indicatorpairs <- matrix_combined_df_combo %>%
    filter(relationship == 1) %>%
    filter(from != to) %>% ## Remove identity 
    filter(from_theme == "Governance" | to_theme == "Governance") %>%
    select(from, to)

# Now remove duplicate pairings (regardless of their order in to or from columns)
# function(x) is defining a function that sorts the elements of each row of the data frame data, and then concatenates them into a single string with "-" as the separator. This is done for each row of the data frame using apply, resulting in a vector of sorted pairs of "from" and "to" values for each row.
  sorted_pairs <- apply(indicatorpairs, 1, function(x) paste(sort(x), collapse = " AND "))
    
# Create a boolean column that marks the second occurence of a pair as a duplicate
  duplicate_pairs <- as.data.frame(duplicated(sorted_pairs) | duplicated(sorted_pairs, fromLast = TRUE))
  duplicate_pairs <- duplicate_pairs %>%
    rename(duplicate = 1)
  
# Add in the duplication information to the sorted pairs
  searchterms <- cbind(sorted_pairs, duplicate_pairs) %>%
    # Drop the duplicate rows
    filter(duplicate != TRUE) %>%
    # Rename 
    rename(naive_search = 1) %>%
    select(-c(duplicate))

# Now split back up into multiple columns
   searchterms <- searchterms %>%
     tidyr::separate(naive_search, c("concept 1", "concept 2"), sep = " AND ")
    
  # Manually revise some search terms
    # Create a find and replace function:
    findreplace <- function(x, y, data) {
      for (i in seq_along(x)) {
        data <- mutate(data, across(everything(), ~ gsub(x[i], y[i], .x)))
      }
      return(data)
    }
   
    changefrom <- c("NCD-Protect", "NCD-Risk", "Food system pathway", "All 5 food groups")
    changeto <- c("dietary protection from non-communicable disease", "dietary risk of non-communicable disease", "food system transformation pathway", "consuming all essential food groups")
    searchterms <- findreplace(changefrom, changeto, searchterms) 
    searchterms <- searchterms %>% mutate(across(everything(), tolower))
    changefrom <- c("milan", "gdp")
    changeto <- c("Milan", "GDP")
    searchterms <- findreplace(changefrom, changeto, searchterms) 
    
# Save to the literature search folder as .csv
    writexl::write_xlsx(searchterms, path = file.path(data_in, "Search terms.xlsx"), col_names = TRUE)
   
```

$~$

# *Automated Literature Search*

#### Create functions needed
```{r}
ST_Build <- function(term){
  # input: terms, a string  
  #   example: "food OR nutrition"
  # 
  # output: search_term, a string with proper syntax for 
  #           search phrase build 
  # 
  #   example: \"(food OR nutrition)\" 
  
  
  # check if contains OR operators 
  if (stringr::str_detect(term, "OR")){
    
    search_term = paste0('\"(', term, ')\"')
    
  }
  else {
    
    search_term = paste0('\"', term, '\"')
  }
  
  return(search_term)
}

SP_Build_normal <- function(search_terms){
  # function: SearchPhraseBuild normal 
  # input: search_terms, a character vector, 
  #         example: c("food", "nutrition")
  #
  # output: search_phrase, a search phrase in Dimensions Query Syntax 
  #      if search type = normal: 
  #           return in syntax: for \"food\" and for \"nutrition\"
  # 
  # assumptions: 
  #   1. established connections with dimensions API 
  #   2. valid search terms 
  # 
  # dependency: ST_Build 
  
  # n tracks number of terms in the terms 
  n = 0 
  for (char in search_terms){
    char1 = ST_Build(char)
    n = n + 1 
    
    # n=1 -> init search phrase 
    if (n < 2 ){
      search_phrase = paste0("for ", char1)
    }
    # inductive step 
    else {
      search_phrase = paste0(search_phrase, " and for ", char1)
    }
  }
  
  return(search_phrase)
  
}

QueryBuild <- function(search_phrase, search_type){
  # function: QueryBuild
  # input: search_phrase, a Dimensions search phrase 
  #        search_type, whether "concepts" or "normal"
  #
  # output: query, a Dimensions query 
  # 
  # assumptions: 
  #   1. established connections with dimensions API 
  #   2. valid search terms 
  # 
  
  # query_start = "search publications "
  query_start = "search publications in title_abstract_only "
  
  query_output = " return publications [basics + abstract + doi + pmcid + pmid ]"
  
  # query_output = " return publications [basics + abstract + doi + pmcid + pmid + concepts_scores ]"


  if (search_type == "concepts"){
      query_search = paste0("where ", search_phrase, 
                            " and year in [ 1900 : 2024 ]",
                            " and type in [ \"article\" ]")
  }
  else if (search_type == "normal"){
      query_search = paste0(search_phrase,
                            " where year in [ 1900 : 2024 ]",
                            " and type in [ \"article\" ]")
  }

  
  query = paste0(query_start, query_search, query_output)
  
  return(query)
}  

DimRequest <- function(query){
  # function: dim_request 
  # input: query, a dimensionsR syntax query 
  # output: lit, a list that includes results 
  #       from search string pull from dimensions 
  # 
  # assumptions: 
  #   1. established connections with dimensions API 
  #   2. valid search strings 
  # 
  
  res <- dimensionsR::dsApiRequest(token = token, 
                                 query = query,  
                                 limit = 0, verbose = TRUE)
  
  return(res)
  
}

assign_char <- function(char){
  if (length(char) == 0){
    return (" ")
  }
  else return(char) 
}

```

## search indicator sheet and export results 

### import, extract search strings 
```{r}
# read search terms from xlsx 
search_terms <- readxl::read_excel(file.path(data_in, "Search terms.xlsx"))

# combine terms into one column 
search_terms <- search_terms %>% tidyr::unite(col = "string_vec", 
                                              sep = " AND ", na.rm = TRUE )

# convert terms into character vector 
search_terms <- search_terms %>% dplyr::pull(1)

# convert vector into a list of character vectors 
search_terms <- search_terms %>% stringr::str_split(pattern = " AND ")


```


### using search terms to create standard query 
```{r}
search_phrases <- lapply(search_terms, 
                         SP_Build_normal)

query_list <- lapply(search_phrases, QueryBuild,
                     search_type = "normal")

search_result <- lapply(query_list, DimRequest)

```


### Extract data from search results 
```{r}
# extract search terms 
# bind every search into a data frame 
# double check on query results 
for (i in 1:length(search_result)){
  if (typeof(search_result[[i]]) == "double"){
      cat("index = ", i, "\n")
      # search_result[[i]] = DimRequest(query_list[[i]])
  }
}

result_1 <- dplyr::bind_rows(search_result, .id = "id")

search_terms_df_1 <- readxl::read_excel("Input Data/Concepts terms revised_2024.xlsx")
                   
# add id column 
search_terms_df_1 <- search_terms_df_1 %>% tibble::rowid_to_column()
search_terms_df_1 <- search_terms_df_1 %>% 
  dplyr::mutate(id = as.character(rowid)) %>%
  dplyr::select(-rowid)

# combine results 
search_terms_df_1 <- search_terms_df_1 %>% 
  dplyr::left_join(result_1, by = join_by(id))

# replace NAs in results 
search_terms_df_1 <- search_terms_df_1 %>% 
  dplyr::mutate(total_count = tidyr::replace_na(total_count, 0))

search_terms_df_1 <- search_terms_df_1 %>% dplyr::select(-c(data, item)) 

search_terms_df_1 <- unique(search_terms_df_1)

# export results 
openxlsx::write.xlsx(search_terms_df_1, "searchresults_1.xlsx")

```

### Use Python to extract further scripts 
```{python}

# header: 
# file purpose: 
#   1. access Dimensions database 
#   2. download scripts 
#   3. 
# python version: 3.10.4 

# load packages 
import pandas as pd 
import os
import dimcli
import re 
import math

# define functions 

def extract_n(extract_limit):
    """
    purpose: extract from dimensions in large batch size (limit = 500)
    note: if bigger than limit 500, Dimensions API could return error for query taking too long 
    """

    limit = extract_limit

    for index in range(query_len):
        query = query_list["query"][index]
        if type(query) != str:
            continue 
        print(query)
        data = dsl.query_iterative(query, limit=limit, verbose=True, force=True).as_dataframe()
        filename = "Output/Total_output/result_" + str(id_list.at[index]) + ".xlsx"
        data.to_excel(filename)
        print(filename)
        index += 1 

def extract_q_index(q_file_list):
    """
    extract q index to re-rerun output extraction from Dimensions Database 
    
    input: 
        q_file_list: a pandas dataframe that has list of filenames of files that needed to be re-reun 

    output: 
        q_index: a index that has the query that needed to be re-run 
    """
    q_index = [] 
    for file in q_file_list:
        index = re.search('[0-9]+', file).group(0)
        q_index.append(int(index))

    return(q_index)


# set working dir 
os.chdir("WORKING DIR")

# load Excel file for query 
file = "search terms_result_7.xlsx"
query_list = pd.read_excel(file)


# login Dimensions 
dimcli.login() # requires dimcli init and API key if not set 
dsl = dimcli.Dsl()

# loop through and saves data as data frames 
# and then save data frames as 
query_len = len(query_list["query"])
id_list = query_list["id"]


"""
commented-out to prevent override (1)

extract_n(extract_limit = 500)

"""

# note: there are many files where the script cannot get all results 
#   due to evaluation error and API taking too long 

# index of files with incomplete files 
# here q_index corresponds to file names xlsx and nth query 

# this is the manual part of the script - we use terminal output from the python script 
# and save them to excel to analyse which files we need to re-run 
# we can log terminal output by using terminal: 
# /usr/local/bin/python3 "lit_search.py" &> out.txt
# then generate out.txt to xlsx to further analyse 

# extract q_index using pandas and excel files 
file_2 = "lit_search_ouput.xlsx"
output_df = pd.read_excel(file_2, sheet_name="Total_Log_1")
q_file_list = output_df.loc[output_df['Re-run file index'] == 1]['Log Output']
q_index = extract_q_index(q_file_list)

# loop through q_index with smaller iteration 
"""
commented out to prevent overwrite (2)

for index in q_index:
    query_index = pd.Index(id_list).get_loc(index)
    query = query_list["query"][query_index]
    print(query)
    data = dsl.query_iterative(query, limit=100, verbose=True, force=True).as_dataframe()
    filename = "Output/Total_output/result_" + str(index) + ".xlsx"
    data.to_excel(filename)
    print(filename)
"""

# loop through q_index with another iteration (limit = 10)
# output_df = pd.read_excel(file_2, sheet_name="Total_Log_2")
# q_file_list = output_df.loc[output_df['Re-run file index'] == 1]['Log Output']
# q_index = extract_q_index(q_file_list)

q_index = [159, 169, 235, 234]

for index in q_index:
    query_index = pd.Index(id_list).get_loc(index)
    query = query_list["query"][query_index]
    print(query)

    # retrieve current data 
    filename = "Output/Total_output/result_" + str(index) + ".xlsx"
    data = pd.read_excel(filename)

    print(filename)
    length = math.floor(len(data) / 100) * 100 
    try:
        data_2 = pd.DataFrame(dsl.query_iterative(query, limit=10, skip = length, verbose=True, force=True))
    except ValueError:
        print("trying new dataframe method")
        data_2 = dsl.query_iterative(query, limit=10, skip = length, verbose=True, force=True).as_dataframe()

    data_whole = pd.concat([data.head(length), data_2], ignore_index= True)
    data_whole.to_excel(filename)

```

### Use R to import Python output and clean them 
```{r}

# 1. import data 

file_list <- list.files(path = "./Output/Total_output", pattern = "^result",
                        full.names = TRUE)

# the strings are not sorted alphabetically 
file_list <- stringr::str_sort(file_list, numeric = TRUE)

df_list <- lapply(file_list, readxl::read_excel, col_types = "text")

result_df <- dplyr::bind_rows(df_list, .id = "id")

# remove row id 
result_df <- result_df %>% dplyr::select(-`...1`)

# clean up 
remove(df_list)

# 2. remove not relevant titles 

# check Poster Session (include caps and no caps)

poster_df <- result_df %>% 
  dplyr::filter(stringr::str_detect(result_df$title, 
                                    stringr::fixed("poster session", 
                                                   ignore_case = TRUE)))


# filter out poster sessions 
result_df <- result_df %>% dplyr::filter(!stringr::str_detect(result_df$title, 
                                         stringr::fixed("poster session", 
                                         ignore_case = TRUE)))


# 3. remove abstract and title with non English languages 

result_df <- result_df %>% dplyr::mutate(text = paste0(title, " ", abstract))


result_df <- result_df %>% dplyr::mutate(cld2 = cld2::detect_language(text = text),
                            cld3 = cld3::detect_language(text = text))


# check on non Eng classifications 
non_EN_df <- result_df %>% dplyr::filter(cld2 != "en" | cld3 != "en")

# save df for review 
# openxlsx::write.xlsx(non_EN_df, file = "non_en.xlsx")

# we filter out non english texts 
result_df <- result_df %>% dplyr::filter(cld2 == "en" & cld3 == "en") # removed non english articles 

# save results 
result_df <- result_df %>% dplyr::select(-c(cld2, cld3, text))

# summarize how many articles are there in each query 
result_count_df <- result_df %>% dplyr::group_by(id) %>%
  dplyr::summarise(num_of_articles = n())

# save results 
result_count_df <- result_count_df %>% dplyr::mutate(id = as.numeric(id))


```

### Merge all results together 
```{r}
# merge in indicator 
search_terms_df_1 <- readxl::read_excel("searchresults_1.xlsx")

# combine results 
search_terms_df_1 <- search_terms_df_1 %>% 
  dplyr::left_join(result_count_df, by = join_by(id))

# filter only governance indicator queries 
search_terms_df_1 <- search_terms_df_1 %>% 
  dplyr::filter(!is.na(title))

# check total counts by query_id 
search_terms_df_1 %>% dplyr::group_by(id) %>% 
  dplyr::summarise(total = n())

# export to csv gz 
# commented out to prevent override 
# readr::write_csv(search_terms_df_1, "gov_result.csv.gz")

# save results
openxlsx::write.xlsx(search_terms_df_1, "Search results_input to screening.xlsx")
```


### Manual screening with the following exclusion criteria:
- Not in English (that was not caught by the automated screening)
- Duplicates within the same indicator pair search, incomplete titles (e.g., “book review”)
- Any titles that indicate complete irrelevance to both indicators searched

$~$ 

Load screened results
```{r}
search_results <- readxl::read_excel(path = file.path(data_out, "Search results_screened.xlsx"))
```
